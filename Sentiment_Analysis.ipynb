{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMGdSLqGAxq4",
        "outputId": "8552c829-a01f-4bf0-fa42-75584e737a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZEZEtPxBwl1",
        "outputId": "0d4dcc59-f341-43df-ea3f-796003f774ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim.lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import gensim \n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec  \n",
        "#from torchnlp.word_to_vector import GloVe, FastText\n",
        "import torchtext.data as ttd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WordPunctTokenizer, word_tokenize, sent_tokenize, TweetTokenizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "#from warnings import simplefilter\n",
        "#simplefilter(action='ignore', category=FutureWarning)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiUoQAHrBwje"
      },
      "source": [
        "folder=Path('/content/gdrive/My Drive/NLP')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiET9cWpB_Do"
      },
      "source": [
        "**Text pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKH-9V1xBwh2"
      },
      "source": [
        "df = pd.read_csv(folder / 'train1.csv', encoding='ISO-8859-1')\n",
        "#print(df.columns)\n",
        "\n",
        "#df.describe()\n",
        "\n",
        "df_test1 = pd.read_csv(folder / 'test1.csv', encoding='ISO-8859-1')\n",
        "#print(df.columns)\n",
        "\n",
        "#df_test1.describe()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1vTaRPMBwf3",
        "outputId": "7cefe432-dbc9-40f4-d098-c8b1bd641200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97670</td>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               text  target\n",
              "0  86426  @USER She should ask a few native Americans wh...       1\n",
              "1  16820  Amazon is investigating Chinese employees who ...       0\n",
              "2  62688  @USER Someone should'veTaken\" this piece of sh...       1\n",
              "3  43605  @USER @USER Obama wanted liberals &amp; illega...       0\n",
              "4  97670                  @USER Liberals are all Kookoo !!!       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA3afTGqepcO",
        "outputId": "b5de36db-f54f-4f53-8d02-8b4e84544fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_test1.head()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home youâre drunk!!! @USER #M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77444</td>\n",
              "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13384</td>\n",
              "      <td>@USER Canada doesnât need another CUCK! We a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54920</td>\n",
              "      <td>@USER @USER @USER It should scare every Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56117</td>\n",
              "      <td>@USER @USER @USER @USER LOL!!!   Throwing the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               text\n",
              "0  90194  @USER @USER Go home youâre drunk!!! @USER #M...\n",
              "1  77444                   @USER @USER Oh noes! Tough shit.\n",
              "2  13384  @USER Canada doesnât need another CUCK! We a...\n",
              "3  54920  @USER @USER @USER It should scare every Americ...\n",
              "4  56117  @USER @USER @USER @USER LOL!!!   Throwing the ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aHlNf1ZBwcx"
      },
      "source": [
        "# drop unnecessary columns\n",
        "df = df.drop([\"id\"], axis=1)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve8OhlDdBwYQ",
        "outputId": "bda2c31e-d2fd-4dd7-9454-6e76912c6da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  @USER She should ask a few native Americans wh...       1\n",
              "1  Amazon is investigating Chinese employees who ...       0\n",
              "2  @USER Someone should'veTaken\" this piece of sh...       1\n",
              "3  @USER @USER Obama wanted liberals &amp; illega...       0\n",
              "4                  @USER Liberals are all Kookoo !!!       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJxKfV_9BwWG"
      },
      "source": [
        "#pre-processing\n",
        "#=================\n",
        "df[\"text\"]=df[\"text\"].str.lower()  #convert to lower case\n",
        "df[\"text\"]=df[\"text\"].str.replace('\\d+','') # remove numbers\n",
        "df[\"text\"]=df[\"text\"].str.replace('<.*?>','') # remove HTML tags\n",
        "df[\"text\"]=df[\"text\"].str.replace('[^@\\w\\s]','') # remove punctuation  \n",
        "\n",
        "#print(df)\n",
        "\n",
        "df_test1[\"text\"]=df_test1[\"text\"].str.lower()  #convert to lower case\n",
        "df_test1[\"text\"]=df_test1[\"text\"].str.replace('\\d+','') # remove numbers\n",
        "df_test1[\"text\"]=df_test1[\"text\"].str.replace('<.*?>','') # remove HTML tags\n",
        "df_test1[\"text\"]=df_test1[\"text\"].str.replace('[^@\\w\\s]','') # remove punctuation  \n",
        "\n",
        "#print(df)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jszFT-8BwTQ",
        "outputId": "d504a110-96ee-462f-8a25-3a58af1f5875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# stemming\n",
        "#===========\n",
        "st = SnowballStemmer('english')\n",
        "df['text'] =df['text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "print(df)\n",
        "\n",
        "df_test1['text'] =df_test1['text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "print(df_test1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text  target\n",
            "0     @user she should ask a few nativ american what...       1\n",
            "1     amazon is investig chines employe who are sell...       0\n",
            "2     @user someon shouldvetaken this piec of shit t...       1\n",
            "3     @user @user obama want liber amp illeg to move...       0\n",
            "4                            @user liber are all kookoo       1\n",
            "...                                                 ...     ...\n",
            "9341                        @user @user but gun control       0\n",
            "9342  @user ðððððð if i say you are mad now you will...       0\n",
            "9343  @user @user @user @user @user @user @user @use...       0\n",
            "9344  @user and whi report this garbag we dont give ...       1\n",
            "9345                                        @user pussi       1\n",
            "\n",
            "[9346 rows x 2 columns]\n",
            "         id                                               text\n",
            "0     90194  @user @user go home youâr drunk @user maga tru...\n",
            "1     77444                      @user @user oh noe tough shit\n",
            "2     13384  @user canada doesnât need anoth cuck we alread...\n",
            "3     54920  @user @user @user it should scare everi americ...\n",
            "4     56117  @user @user @user @user lol throw the bullshit...\n",
            "...     ...                                                ...\n",
            "3889  90041  @user @user billi you have a short memori obam...\n",
            "3890  98824   @user she is not the brightest light on the tree\n",
            "3891  95338  @user sometim i get strong vibe from peopl and...\n",
            "3892  67210  benidorm â creamfield â maga â not too shabbi ...\n",
            "3893  46552  spanishreveng vs justic humanright and freedom...\n",
            "\n",
            "[3894 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzamA6WKBwRI",
        "outputId": "15a5c9a7-fa8d-4a1c-bc79-777d6db910a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# remove stopwords\n",
        "#====================\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "print(df)\n",
        "\n",
        "df_test1['text'] = df_test1['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "print(df_test1)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text  target\n",
            "0                       @user ask native americans take       1\n",
            "1     amazon investigating chinese employees selling...       0\n",
            "2      @user someone shouldvetaken piece shit volcano ð       1\n",
            "3     @user @user obama wanted liberals amp illegals...       0\n",
            "4                                 @user liberals kookoo       1\n",
            "...                                                 ...     ...\n",
            "9341                            @user @user gun control       0\n",
            "9342                  @user ðððððð say mad say im tired       0\n",
            "9343  @user @user @user @user @user @user @user @use...       0\n",
            "9344                @user report garbage dont give crap       1\n",
            "9345                                        @user pussy       1\n",
            "\n",
            "[9346 rows x 2 columns]\n",
            "         id                                               text\n",
            "0     90194  @user @user go home youâre drunk @user maga tr...\n",
            "1     77444                     @user @user oh noes tough shit\n",
            "2     13384  @user canada doesnât need another cuck already...\n",
            "3     54920  @user @user @user scare every american playing...\n",
            "4     56117  @user @user @user @user lol throwing bullshit ...\n",
            "...     ...                                                ...\n",
            "3889  90041  @user @user billy short memory obama tried get...\n",
            "3890  98824                         @user brightest light tree\n",
            "3891  95338  @user sometimes get strong vibes people manâs ...\n",
            "3892  67210      benidorm â creamfields â maga â shabby summer\n",
            "3893  46552  spanishrevenge vs justice humanrights freedomo...\n",
            "\n",
            "[3894 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaYNaZExBwOw",
        "outputId": "d5272ab5-dcaf-426f-b703-4c70ccebd9df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#word tokenizer\n",
        "#===============\n",
        "# using tweetokenizer to remove @ handles. WordPunctTokenizer does not keep handles together.\n",
        "\n",
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "df['text']=df['text'].apply(lambda row: \" \".join(tknzr.tokenize(row)))\n",
        "print(df)\n",
        "\n",
        "df_test1['text']=df_test1['text'].apply(lambda row: \" \".join(tknzr.tokenize(row)))\n",
        "print(df_test1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text  target\n",
            "0                             ask native americans take       1\n",
            "1     amazon investigating chinese employees selling...       0\n",
            "2            someone shouldvetaken piece shit volcano ð       1\n",
            "3     obama wanted liberals amp illegals move red st...       0\n",
            "4                                       liberals kookoo       1\n",
            "...                                                 ...     ...\n",
            "9341                                        gun control       0\n",
            "9342                           ððð say mad say im tired       0\n",
            "9343   retweet complete amp followed patriotsðºððªïðââï       0\n",
            "9344                      report garbage dont give crap       1\n",
            "9345                                              pussy       1\n",
            "\n",
            "[9346 rows x 2 columns]\n",
            "         id                                               text\n",
            "0     90194          go home youâre drunk maga trump ððºðð url\n",
            "1     77444                                 oh noes tough shit\n",
            "2     13384  canada doesnât need another cuck already enoug...\n",
            "3     54920    scare every american playing hockey warped puck\n",
            "4     56117  lol throwing bullshit flag nonsense putuporshu...\n",
            "...     ...                                                ...\n",
            "3889  90041  billy short memory obama tried get commonsense...\n",
            "3890  98824                               brightest light tree\n",
            "3891  95338  sometimes get strong vibes people manâs vibe t...\n",
            "3892  67210      benidorm â creamfields â maga â shabby summer\n",
            "3893  46552  spanishrevenge vs justice humanrights freedomo...\n",
            "\n",
            "[3894 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjjP4pC4-94b",
        "outputId": "79a3d784-8596-4b49-d9eb-c7cae83d15b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['text']=df['text'].str.replace('[^A-Za-z0-9\\s]','') # remove special characters \n",
        "df_test1[\"text\"]=df_test1[\"text\"].str.replace('[^A-Za-z0-9\\s]','') # remove special characters \n",
        "\n",
        "print(df)\n",
        "print(df_test1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text  target\n",
            "0                             ask native americans take       1\n",
            "1     amazon investigating chinese employees selling...       0\n",
            "2             someone shouldvetaken piece shit volcano        1\n",
            "3     obama wanted liberals amp illegals move red st...       0\n",
            "4                                       liberals kookoo       1\n",
            "...                                                 ...     ...\n",
            "9341                                        gun control       0\n",
            "9342                               say mad say im tired       0\n",
            "9343             retweet complete amp followed patriots       0\n",
            "9344                      report garbage dont give crap       1\n",
            "9345                                              pussy       1\n",
            "\n",
            "[9346 rows x 2 columns]\n",
            "         id                                               text\n",
            "0     90194                go home youre drunk maga trump  url\n",
            "1     77444                                 oh noes tough shit\n",
            "2     13384  canada doesnt need another cuck already enough...\n",
            "3     54920    scare every american playing hockey warped puck\n",
            "4     56117  lol throwing bullshit flag nonsense putuporshu...\n",
            "...     ...                                                ...\n",
            "3889  90041  billy short memory obama tried get commonsense...\n",
            "3890  98824                               brightest light tree\n",
            "3891  95338  sometimes get strong vibes people mans vibe te...\n",
            "3892  67210         benidorm  creamfields  maga  shabby summer\n",
            "3893  46552  spanishrevenge vs justice humanrights freedomo...\n",
            "\n",
            "[3894 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi4eHVdhBwMa",
        "outputId": "72345a72-93c5-426b-853a-e66f92922392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['target'].value_counts()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6220\n",
              "1    3126\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYnLFyOZBwKP",
        "outputId": "261065fa-acf3-42b5-f414-54a3a3a594db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.columns = ['data', 'labels']\n",
        "df.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ask native americans take</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amazon investigating chinese employees selling...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>someone shouldvetaken piece shit volcano</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>obama wanted liberals amp illegals move red st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>liberals kookoo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  labels\n",
              "0                          ask native americans take       1\n",
              "1  amazon investigating chinese employees selling...       0\n",
              "2          someone shouldvetaken piece shit volcano        1\n",
              "3  obama wanted liberals amp illegals move red st...       0\n",
              "4                                    liberals kookoo       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeKXl_dAlqpl"
      },
      "source": [
        "df_test1.columns = ['id', 'data']\n",
        "df_test2 = df_test1.copy()\n",
        "\n",
        "df_test2 = df_test2.drop([\"id\"], axis=1)\n",
        "df_test2.head()\n",
        "\n",
        "# adding a dummy column of labels = all are set to 1\n",
        "df_test2['labels']=1"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzF_xhRXk4dg"
      },
      "source": [
        "df.to_csv(folder / 'train2.csv', index=False)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6TpGQLkiDxY"
      },
      "source": [
        "df_test2.to_csv(folder / 'test2.csv', index=False)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLarBhmWk8k4"
      },
      "source": [
        "TEXT = ttd.Field(\n",
        "    sequential=True,\n",
        "    batch_first=True,\n",
        "    lower=False,\n",
        "    tokenize='spacy',\n",
        "    pad_first=True)\n",
        "\n",
        "LABEL = ttd.LabelField()\n",
        "#LABEL = ttd.Field(sequential=False, use_vocab=False, is_target=True)\n",
        "\n",
        "dataset = ttd.TabularDataset(\n",
        "    path= folder / 'train2.csv',\n",
        "    format='csv',\n",
        "    skip_header=True,\n",
        "    fields=[('data', TEXT), ('label', LABEL)]\n",
        ")\n",
        "\n",
        "dataset_test1 = ttd.TabularDataset(\n",
        "    path= folder / 'test2.csv',\n",
        "    format='csv',\n",
        "    skip_header=True,\n",
        "    fields=[('data', TEXT), ('label', LABEL)]\n",
        ")"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54USyjp7k8nV"
      },
      "source": [
        "import random\n",
        "SEED=777\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.7,random_state = random.seed(SEED)) # default is 0.7"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGqg48Lzk8rd"
      },
      "source": [
        "SEED=777\n",
        "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(SEED)) # default is 0.7"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVu2Z_c94OHH"
      },
      "source": [
        "SEED=777\n",
        "test_1, test_2 = dataset_test1.split(split_ratio=0.9998, random_state = random.seed(SEED)) # default is 0.7"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2Iq40o4fkv",
        "outputId": "ffb35cd8-7814-4416-f4b3-d5952818a570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Number of training examples: {len(test_1)}')\n",
        "print(f'Number of validation examples: {len(test_2)}')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 3893\n",
            "Number of validation examples: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7G3d7X_k8i2",
        "outputId": "89f658ca-eb91-4a61-882b-194ff4135a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_dataset)}')\n",
        "print(f'Number of validation examples: {len(valid_dataset)}')\n",
        "print(f'Number of testing examples: {len(test_dataset)}')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 4579\n",
            "Number of validation examples: 1963\n",
            "Number of testing examples: 2804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52zSGp7Jrmnb",
        "outputId": "d5dfce9e-ce49-4ec6-843a-09688616df4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Number of actual testing examples: {len(test_1)}')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of actual testing examples: 3893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z12lEn2AlpBC"
      },
      "source": [
        "#Using Pretrained Embeddings\n",
        "#============================\n",
        "\n",
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_dataset, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hei4-TMTlpNC",
        "outputId": "eb0b206f-75fa-4e2e-efab-493aa073fbc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "LABEL.build_vocab(train_dataset)\n",
        "vocab_text = TEXT.vocab\n",
        "vocab_text.stoi"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'<unk>': 0,\n",
              "             '<pad>': 1,\n",
              "             'nt': 2,\n",
              "             'url': 3,\n",
              "             'liberals': 4,\n",
              "             'gun': 5,\n",
              "             'control': 6,\n",
              "             'antifa': 7,\n",
              "             'like': 8,\n",
              "             'maga': 9,\n",
              "             's': 10,\n",
              "             'do': 11,\n",
              "             'people': 12,\n",
              "             'conservatives': 13,\n",
              "             'trump': 14,\n",
              "             ' ': 15,\n",
              "             'i': 16,\n",
              "             'one': 17,\n",
              "             'know': 18,\n",
              "             'get': 19,\n",
              "             'would': 20,\n",
              "             'amp': 21,\n",
              "             'think': 22,\n",
              "             'm': 23,\n",
              "             'right': 24,\n",
              "             'good': 25,\n",
              "             'that': 26,\n",
              "             'us': 27,\n",
              "             'shit': 28,\n",
              "             're': 29,\n",
              "             'never': 30,\n",
              "             'going': 31,\n",
              "             'want': 32,\n",
              "             'time': 33,\n",
              "             'really': 34,\n",
              "             'see': 35,\n",
              "             'go': 36,\n",
              "             'need': 37,\n",
              "             'love': 38,\n",
              "             'even': 39,\n",
              "             'you': 40,\n",
              "             'say': 41,\n",
              "             'ca': 42,\n",
              "             'vote': 43,\n",
              "             'way': 44,\n",
              "             'its': 45,\n",
              "             'back': 46,\n",
              "             'make': 47,\n",
              "             'left': 48,\n",
              "             'well': 49,\n",
              "             'much': 50,\n",
              "             'still': 51,\n",
              "             'party': 52,\n",
              "             'he': 53,\n",
              "             'president': 54,\n",
              "             'take': 55,\n",
              "             'look': 56,\n",
              "             'democrats': 57,\n",
              "             'country': 58,\n",
              "             'stop': 59,\n",
              "             'could': 60,\n",
              "             'man': 61,\n",
              "             'years': 62,\n",
              "             'does': 63,\n",
              "             'great': 64,\n",
              "             'nothing': 65,\n",
              "             'also': 66,\n",
              "             'better': 67,\n",
              "             'keep': 68,\n",
              "             'lol': 69,\n",
              "             'many': 70,\n",
              "             'believe': 71,\n",
              "             'another': 72,\n",
              "             'did': 73,\n",
              "             'said': 74,\n",
              "             'u': 75,\n",
              "             'hope': 76,\n",
              "             'thing': 77,\n",
              "             'white': 78,\n",
              "             'away': 79,\n",
              "             'everyone': 80,\n",
              "             'liberal': 81,\n",
              "             've': 82,\n",
              "             'america': 83,\n",
              "             'they': 84,\n",
              "             'care': 85,\n",
              "             'god': 86,\n",
              "             'trying': 87,\n",
              "             'women': 88,\n",
              "             'kavanaugh': 89,\n",
              "             'yes': 90,\n",
              "             'call': 91,\n",
              "             'got': 92,\n",
              "             'is': 93,\n",
              "             'life': 94,\n",
              "             'guns': 95,\n",
              "             'new': 96,\n",
              "             'work': 97,\n",
              "             'every': 98,\n",
              "             'support': 99,\n",
              "             'ever': 100,\n",
              "             'laws': 101,\n",
              "             'money': 102,\n",
              "             'fuck': 103,\n",
              "             'getting': 104,\n",
              "             'since': 105,\n",
              "             'sure': 106,\n",
              "             'ass': 107,\n",
              "             'help': 108,\n",
              "             'thank': 109,\n",
              "             'woman': 110,\n",
              "             'fucking': 111,\n",
              "             'law': 112,\n",
              "             'oh': 113,\n",
              "             'someone': 114,\n",
              "             'everything': 115,\n",
              "             'hate': 116,\n",
              "             'let': 117,\n",
              "             'old': 118,\n",
              "             'please': 119,\n",
              "             'big': 120,\n",
              "             'tell': 121,\n",
              "             'wrong': 122,\n",
              "             'always': 123,\n",
              "             'day': 124,\n",
              "             'she': 125,\n",
              "             'show': 126,\n",
              "             'enough': 127,\n",
              "             'bad': 128,\n",
              "             'first': 129,\n",
              "             'saying': 130,\n",
              "             'give': 131,\n",
              "             'part': 132,\n",
              "             'violence': 133,\n",
              "             'world': 134,\n",
              "             'follow': 135,\n",
              "             'government': 136,\n",
              "             'person': 137,\n",
              "             'funny': 138,\n",
              "             'made': 139,\n",
              "             'anyone': 140,\n",
              "             'come': 141,\n",
              "             'hell': 142,\n",
              "             'news': 143,\n",
              "             'actually': 144,\n",
              "             'american': 145,\n",
              "             'done': 146,\n",
              "             'long': 147,\n",
              "             'may': 148,\n",
              "             'maybe': 149,\n",
              "             'point': 150,\n",
              "             'something': 151,\n",
              "             'truth': 152,\n",
              "             'watch': 153,\n",
              "             'guy': 154,\n",
              "             'job': 155,\n",
              "             'needs': 156,\n",
              "             'anything': 157,\n",
              "             'black': 158,\n",
              "             'game': 159,\n",
              "             'mean': 160,\n",
              "             'obama': 161,\n",
              "             'put': 162,\n",
              "             'talking': 163,\n",
              "             'far': 164,\n",
              "             'real': 165,\n",
              "             'state': 166,\n",
              "             'thought': 167,\n",
              "             'best': 168,\n",
              "             'kind': 169,\n",
              "             'lying': 170,\n",
              "             'making': 171,\n",
              "             'next': 172,\n",
              "             'political': 173,\n",
              "             'start': 174,\n",
              "             'talk': 175,\n",
              "             'things': 176,\n",
              "             'yet': 177,\n",
              "             'dems': 178,\n",
              "             'lies': 179,\n",
              "             'might': 180,\n",
              "             'name': 181,\n",
              "             'stupid': 182,\n",
              "             'true': 183,\n",
              "             'tweet': 184,\n",
              "             'year': 185,\n",
              "             'free': 186,\n",
              "             'lot': 187,\n",
              "             'media': 188,\n",
              "             'says': 189,\n",
              "             'school': 190,\n",
              "             'try': 191,\n",
              "             'beautiful': 192,\n",
              "             'fake': 193,\n",
              "             'lets': 194,\n",
              "             'republicans': 195,\n",
              "             'change': 196,\n",
              "             'conservative': 197,\n",
              "             'd': 198,\n",
              "             'last': 199,\n",
              "             'little': 200,\n",
              "             'looking': 201,\n",
              "             'problem': 202,\n",
              "             'sorry': 203,\n",
              "             'stand': 204,\n",
              "             'use': 205,\n",
              "             'used': 206,\n",
              "             'already': 207,\n",
              "             'find': 208,\n",
              "             'must': 209,\n",
              "             'supporters': 210,\n",
              "             'understand': 211,\n",
              "             'kag': 212,\n",
              "             'reason': 213,\n",
              "             'americans': 214,\n",
              "             'bitch': 215,\n",
              "             'end': 216,\n",
              "             'guess': 217,\n",
              "             'home': 218,\n",
              "             'thanks': 219,\n",
              "             'wo': 220,\n",
              "             'working': 221,\n",
              "             'ask': 222,\n",
              "             'called': 223,\n",
              "             'cause': 224,\n",
              "             'men': 225,\n",
              "             'power': 226,\n",
              "             'yeah': 227,\n",
              "             'sense': 228,\n",
              "             'war': 229,\n",
              "             'group': 230,\n",
              "             'hard': 231,\n",
              "             'liar': 232,\n",
              "             'ok': 233,\n",
              "             'without': 234,\n",
              "             'disgusting': 235,\n",
              "             'exactly': 236,\n",
              "             'family': 237,\n",
              "             'gop': 238,\n",
              "             'happy': 239,\n",
              "             'probably': 240,\n",
              "             'today': 241,\n",
              "             'agree': 242,\n",
              "             'calling': 243,\n",
              "             'crazy': 244,\n",
              "             'knows': 245,\n",
              "             'lie': 246,\n",
              "             'lost': 247,\n",
              "             'means': 248,\n",
              "             'na': 249,\n",
              "             'play': 250,\n",
              "             'remember': 251,\n",
              "             'republican': 252,\n",
              "             'rights': 253,\n",
              "             'absolutely': 254,\n",
              "             'ago': 255,\n",
              "             'comes': 256,\n",
              "             'feel': 257,\n",
              "             'gets': 258,\n",
              "             'girl': 259,\n",
              "             'gon': 260,\n",
              "             'looks': 261,\n",
              "             'seen': 262,\n",
              "             'wants': 263,\n",
              "             'win': 264,\n",
              "             'word': 265,\n",
              "             'around': 266,\n",
              "             'bill': 267,\n",
              "             'else': 268,\n",
              "             'fact': 269,\n",
              "             'makes': 270,\n",
              "             'mind': 271,\n",
              "             'nra': 272,\n",
              "             'ones': 273,\n",
              "             'racist': 274,\n",
              "             'sick': 275,\n",
              "             'twitter': 276,\n",
              "             'using': 277,\n",
              "             'wwgwga': 278,\n",
              "             'amazing': 279,\n",
              "             'crime': 280,\n",
              "             'evil': 281,\n",
              "             'judge': 282,\n",
              "             'public': 283,\n",
              "             'seriously': 284,\n",
              "             'though': 285,\n",
              "             'two': 286,\n",
              "             'walkaway': 287,\n",
              "             'whole': 288,\n",
              "             'are': 289,\n",
              "             'become': 290,\n",
              "             'brexit': 291,\n",
              "             'common': 292,\n",
              "             'constitution': 293,\n",
              "             'democrat': 294,\n",
              "             'either': 295,\n",
              "             'fight': 296,\n",
              "             'guilty': 297,\n",
              "             'heard': 298,\n",
              "             'high': 299,\n",
              "             'house': 300,\n",
              "             'matter': 301,\n",
              "             'seems': 302,\n",
              "             'social': 303,\n",
              "             'violent': 304,\n",
              "             'awesome': 305,\n",
              "             'boy': 306,\n",
              "             'full': 307,\n",
              "             'happen': 308,\n",
              "             'issue': 309,\n",
              "             'live': 310,\n",
              "             'lives': 311,\n",
              "             'open': 312,\n",
              "             'read': 313,\n",
              "             'shot': 314,\n",
              "             'tax': 315,\n",
              "             'there': 316,\n",
              "             'wanted': 317,\n",
              "             'bet': 318,\n",
              "             'blame': 319,\n",
              "             'business': 320,\n",
              "             'coming': 321,\n",
              "             'congress': 322,\n",
              "             'jail': 323,\n",
              "             'kids': 324,\n",
              "             'leave': 325,\n",
              "             'police': 326,\n",
              "             'potus': 327,\n",
              "             'qanon': 328,\n",
              "             'red': 329,\n",
              "             'shooting': 330,\n",
              "             'tcot': 331,\n",
              "             'trumps': 332,\n",
              "             'usa': 333,\n",
              "             'words': 334,\n",
              "             'able': 335,\n",
              "             'book': 336,\n",
              "             'bring': 337,\n",
              "             'children': 338,\n",
              "             'clearly': 339,\n",
              "             'clinton': 340,\n",
              "             'dead': 341,\n",
              "             'different': 342,\n",
              "             'fine': 343,\n",
              "             'found': 344,\n",
              "             'groups': 345,\n",
              "             'hillary': 346,\n",
              "             'hit': 347,\n",
              "             'ill': 348,\n",
              "             'pretty': 349,\n",
              "             'proven': 350,\n",
              "             'question': 351,\n",
              "             'safe': 352,\n",
              "             'took': 353,\n",
              "             'works': 354,\n",
              "             'young': 355,\n",
              "             'act': 356,\n",
              "             'can': 357,\n",
              "             'chicago': 358,\n",
              "             'class': 359,\n",
              "             'cute': 360,\n",
              "             'days': 361,\n",
              "             'facts': 362,\n",
              "             'false': 363,\n",
              "             'following': 364,\n",
              "             'hear': 365,\n",
              "             'hey': 366,\n",
              "             'idiot': 367,\n",
              "             'line': 368,\n",
              "             'listen': 369,\n",
              "             'not': 370,\n",
              "             'paid': 371,\n",
              "             'pay': 372,\n",
              "             'playing': 373,\n",
              "             'politics': 374,\n",
              "             'proud': 375,\n",
              "             'saw': 376,\n",
              "             'speech': 377,\n",
              "             'taking': 378,\n",
              "             'telling': 379,\n",
              "             'via': 380,\n",
              "             'what': 381,\n",
              "             'ai': 382,\n",
              "             'answer': 383,\n",
              "             'behind': 384,\n",
              "             'california': 385,\n",
              "             'case': 386,\n",
              "             'child': 387,\n",
              "             'death': 388,\n",
              "             'deep': 389,\n",
              "             'dude': 390,\n",
              "             'election': 391,\n",
              "             'except': 392,\n",
              "             'holy': 393,\n",
              "             'human': 394,\n",
              "             'imagine': 395,\n",
              "             'kill': 396,\n",
              "             'll': 397,\n",
              "             'place': 398,\n",
              "             'report': 399,\n",
              "             'shut': 400,\n",
              "             'story': 401,\n",
              "             'sucks': 402,\n",
              "             'times': 403,\n",
              "             'wait': 404,\n",
              "             'watching': 405,\n",
              "             'asking': 406,\n",
              "             'church': 407,\n",
              "             'fun': 408,\n",
              "             'head': 409,\n",
              "             'least': 410,\n",
              "             'past': 411,\n",
              "             'realize': 412,\n",
              "             'side': 413,\n",
              "             'th': 414,\n",
              "             'tried': 415,\n",
              "             'was': 416,\n",
              "             'accuser': 417,\n",
              "             'assault': 418,\n",
              "             'attention': 419,\n",
              "             'baby': 420,\n",
              "             'character': 421,\n",
              "             'court': 422,\n",
              "             'deal': 423,\n",
              "             'ford': 424,\n",
              "             'guys': 425,\n",
              "             'history': 426,\n",
              "             'hold': 427,\n",
              "             'innocent': 428,\n",
              "             'instead': 429,\n",
              "             'knew': 430,\n",
              "             'low': 431,\n",
              "             'million': 432,\n",
              "             'nazis': 433,\n",
              "             'poor': 434,\n",
              "             'ruin': 435,\n",
              "             'run': 436,\n",
              "             'sex': 437,\n",
              "             'should': 438,\n",
              "             'shows': 439,\n",
              "             'smart': 440,\n",
              "             'thinks': 441,\n",
              "             'went': 442,\n",
              "             'ya': 443,\n",
              "             'all': 444,\n",
              "             'citizens': 445,\n",
              "             'clear': 446,\n",
              "             'cnn': 447,\n",
              "             'crap': 448,\n",
              "             'criminals': 449,\n",
              "             'destroy': 450,\n",
              "             'donald': 451,\n",
              "             'face': 452,\n",
              "             'fan': 453,\n",
              "             'fascist': 454,\n",
              "             'glad': 455,\n",
              "             'gone': 456,\n",
              "             'hand': 457,\n",
              "             'hands': 458,\n",
              "             'idea': 459,\n",
              "             'less': 460,\n",
              "             'literally': 461,\n",
              "             'lose': 462,\n",
              "             'n': 463,\n",
              "             'nd': 464,\n",
              "             'others': 465,\n",
              "             'patriots': 466,\n",
              "             'r': 467,\n",
              "             'rednationrising': 468,\n",
              "             'second': 469,\n",
              "             'sides': 470,\n",
              "             'terrorist': 471,\n",
              "             'truly': 472,\n",
              "             'turn': 473,\n",
              "             'ur': 474,\n",
              "             'video': 475,\n",
              "             'wonder': 476,\n",
              "             'agenda': 477,\n",
              "             'allow': 478,\n",
              "             'almost': 479,\n",
              "             'attack': 480,\n",
              "             'bc': 481,\n",
              "             'buy': 482,\n",
              "             'canada': 483,\n",
              "             'china': 484,\n",
              "             'damn': 485,\n",
              "             'feinstein': 486,\n",
              "             'hearing': 487,\n",
              "             'miss': 488,\n",
              "             'nation': 489,\n",
              "             'nfl': 490,\n",
              "             'office': 491,\n",
              "             'post': 492,\n",
              "             'race': 493,\n",
              "             'shame': 494,\n",
              "             'soros': 495,\n",
              "             'sounds': 496,\n",
              "             'states': 497,\n",
              "             'thinking': 498,\n",
              "             'together': 499,\n",
              "             'uk': 500,\n",
              "             'victim': 501,\n",
              "             'welcome': 502,\n",
              "             'worst': 503,\n",
              "             'wow': 504,\n",
              "             'abuse': 505,\n",
              "             'argument': 506,\n",
              "             'beat': 507,\n",
              "             'bs': 508,\n",
              "             'bullshit': 509,\n",
              "             'campaign': 510,\n",
              "             'cares': 511,\n",
              "             'check': 512,\n",
              "             'claim': 513,\n",
              "             'corrupt': 514,\n",
              "             'difference': 515,\n",
              "             'elected': 516,\n",
              "             'evidence': 517,\n",
              "             'given': 518,\n",
              "             'goes': 519,\n",
              "             'hopefully': 520,\n",
              "             'hurt': 521,\n",
              "             'illegal': 522,\n",
              "             'important': 523,\n",
              "             'issues': 524,\n",
              "             'known': 525,\n",
              "             'leader': 526,\n",
              "             'lmao': 527,\n",
              "             'murder': 528,\n",
              "             'nazi': 529,\n",
              "             'night': 530,\n",
              "             'none': 531,\n",
              "             'omg': 532,\n",
              "             'order': 533,\n",
              "             'perfect': 534,\n",
              "             'piece': 535,\n",
              "             'policies': 536,\n",
              "             'running': 537,\n",
              "             'sad': 538,\n",
              "             'self': 539,\n",
              "             'soon': 540,\n",
              "             'speak': 541,\n",
              "             'stay': 542,\n",
              "             'strong': 543,\n",
              "             'stuff': 544,\n",
              "             'team': 545,\n",
              "             'texas': 546,\n",
              "             'trash': 547,\n",
              "             'along': 548,\n",
              "             'anymore': 549,\n",
              "             'blue': 550,\n",
              "             'chance': 551,\n",
              "             'correct': 552,\n",
              "             'course': 553,\n",
              "             'dangerous': 554,\n",
              "             'dick': 555,\n",
              "             'disgrace': 556,\n",
              "             'dumb': 557,\n",
              "             'fans': 558,\n",
              "             'fear': 559,\n",
              "             'federal': 560,\n",
              "             'fighting': 561,\n",
              "             'forget': 562,\n",
              "             'gave': 563,\n",
              "             'health': 564,\n",
              "             'joke': 565,\n",
              "             'leftist': 566,\n",
              "             'level': 567,\n",
              "             'likely': 568,\n",
              "             'list': 569,\n",
              "             'majority': 570,\n",
              "             'move': 571,\n",
              "             'movement': 572,\n",
              "             'mr': 573,\n",
              "             'plan': 574,\n",
              "             'proof': 575,\n",
              "             'push': 576,\n",
              "             'ready': 577,\n",
              "             'rest': 578,\n",
              "             'save': 579,\n",
              "             'sexual': 580,\n",
              "             'started': 581,\n",
              "             'supporting': 582,\n",
              "             'top': 583,\n",
              "             'totally': 584,\n",
              "             'tweets': 585,\n",
              "             'voting': 586,\n",
              "             'walk': 587,\n",
              "             'were': 588,\n",
              "             'who': 589,\n",
              "             'worse': 590,\n",
              "             'y': 591,\n",
              "             'actions': 592,\n",
              "             'alone': 593,\n",
              "             'apparently': 594,\n",
              "             'attacks': 595,\n",
              "             'blm': 596,\n",
              "             'carry': 597,\n",
              "             'civil': 598,\n",
              "             'confirmkavanaugh': 599,\n",
              "             'countries': 600,\n",
              "             'criminal': 601,\n",
              "             'defend': 602,\n",
              "             'democratic': 603,\n",
              "             'example': 604,\n",
              "             'friends': 605,\n",
              "             'half': 606,\n",
              "             'heart': 607,\n",
              "             'including': 608,\n",
              "             'justice': 609,\n",
              "             'mouth': 610,\n",
              "             'protect': 611,\n",
              "             'protest': 612,\n",
              "             'rather': 613,\n",
              "             'research': 614,\n",
              "             'stories': 615,\n",
              "             'system': 616,\n",
              "             'taxes': 617,\n",
              "             'terrible': 618,\n",
              "             'tired': 619,\n",
              "             'tories': 620,\n",
              "             'trust': 621,\n",
              "             'winning': 622,\n",
              "             '  ': 623,\n",
              "             'allowed': 624,\n",
              "             'amendment': 625,\n",
              "             'b': 626,\n",
              "             'ban': 627,\n",
              "             'bless': 628,\n",
              "             'choice': 629,\n",
              "             'close': 630,\n",
              "             'continue': 631,\n",
              "             'cut': 632,\n",
              "             'dem': 633,\n",
              "             'doubt': 634,\n",
              "             'dr': 635,\n",
              "             'due': 636,\n",
              "             'eric': 637,\n",
              "             'fall': 638,\n",
              "             'fascists': 639,\n",
              "             'fast': 640,\n",
              "             'favorite': 641,\n",
              "             'friend': 642,\n",
              "             'hateful': 643,\n",
              "             'held': 644,\n",
              "             'join': 645,\n",
              "             'killed': 646,\n",
              "             'killing': 647,\n",
              "             'kkk': 648,\n",
              "             'legal': 649,\n",
              "             'loved': 650,\n",
              "             'members': 651,\n",
              "             'millions': 652,\n",
              "             'months': 653,\n",
              "             'november': 654,\n",
              "             'parents': 655,\n",
              "             'politicians': 656,\n",
              "             'ppl': 657,\n",
              "             'prove': 658,\n",
              "             'pussy': 659,\n",
              "             'rape': 660,\n",
              "             'rule': 661,\n",
              "             'schools': 662,\n",
              "             'seeing': 663,\n",
              "             'single': 664,\n",
              "             'socialist': 665,\n",
              "             'society': 666,\n",
              "             'son': 667,\n",
              "             'strict': 668,\n",
              "             'taken': 669,\n",
              "             'takes': 670,\n",
              "             'terrorists': 671,\n",
              "             'total': 672,\n",
              "             'trudeau': 673,\n",
              "             'values': 674,\n",
              "             'voters': 675,\n",
              "             'wanna': 676,\n",
              "             'wing': 677,\n",
              "             'wish': 678,\n",
              "             'zero': 679,\n",
              "             'account': 680,\n",
              "             'age': 681,\n",
              "             'anti': 682,\n",
              "             'based': 683,\n",
              "             'believes': 684,\n",
              "             'bitter': 685,\n",
              "             'break': 686,\n",
              "             'career': 687,\n",
              "             'charge': 688,\n",
              "             'comment': 689,\n",
              "             'completely': 690,\n",
              "             'cool': 691,\n",
              "             'cops': 692,\n",
              "             'crying': 693,\n",
              "             'die': 694,\n",
              "             'dog': 695,\n",
              "             'domestic': 696,\n",
              "             'eu': 697,\n",
              "             'expect': 698,\n",
              "             'father': 699,\n",
              "             'fbi': 700,\n",
              "             'feeling': 701,\n",
              "             'fix': 702,\n",
              "             'followers': 703,\n",
              "             'fool': 704,\n",
              "             'general': 705,\n",
              "             'giving': 706,\n",
              "             'ground': 707,\n",
              "             'happened': 708,\n",
              "             'have': 709,\n",
              "             'holder': 710,\n",
              "             'idk': 711,\n",
              "             'india': 712,\n",
              "             'it': 713,\n",
              "             'jobs': 714,\n",
              "             'moment': 715,\n",
              "             'obviously': 716,\n",
              "             'pass': 717,\n",
              "             'peoples': 718,\n",
              "             'personally': 719,\n",
              "             'process': 720,\n",
              "             'propaganda': 721,\n",
              "             'questions': 722,\n",
              "             'reality': 723,\n",
              "             'resistance': 724,\n",
              "             'set': 725,\n",
              "             'sit': 726,\n",
              "             'speaks': 727,\n",
              "             'students': 728,\n",
              "             'swamp': 729,\n",
              "             'told': 730,\n",
              "             'tv': 731,\n",
              "             'type': 732,\n",
              "             'unless': 733,\n",
              "             'uses': 734,\n",
              "             'v': 735,\n",
              "             'views': 736,\n",
              "             'voted': 737,\n",
              "             'water': 738,\n",
              "             'week': 739,\n",
              "             'whatever': 740,\n",
              "             'wife': 741,\n",
              "             'worth': 742,\n",
              "             'abortion': 743,\n",
              "             'actual': 744,\n",
              "             'afraid': 745,\n",
              "             'alive': 746,\n",
              "             'aware': 747,\n",
              "             'border': 748,\n",
              "             'borders': 749,\n",
              "             'brain': 750,\n",
              "             'broke': 751,\n",
              "             'brown': 752,\n",
              "             'came': 753,\n",
              "             'christian': 754,\n",
              "             'climate': 755,\n",
              "             'crimes': 756,\n",
              "             'culture': 757,\n",
              "             'dc': 758,\n",
              "             'definitely': 759,\n",
              "             'drunk': 760,\n",
              "             'entire': 761,\n",
              "             'fault': 762,\n",
              "             'folks': 763,\n",
              "             'followed': 764,\n",
              "             'form': 765,\n",
              "             'freedom': 766,\n",
              "             'future': 767,\n",
              "             'hat': 768,\n",
              "             'hatred': 769,\n",
              "             'honestly': 770,\n",
              "             'housing': 771,\n",
              "             'hypocrisy': 772,\n",
              "             'investigation': 773,\n",
              "             'longer': 774,\n",
              "             'metoo': 775,\n",
              "             'military': 776,\n",
              "             'names': 777,\n",
              "             'nice': 778,\n",
              "             'opinion': 779,\n",
              "             'platform': 780,\n",
              "             'politically': 781,\n",
              "             'prison': 782,\n",
              "             'pro': 783,\n",
              "             'progressive': 784,\n",
              "             'puerto': 785,\n",
              "             'quite': 786,\n",
              "             'record': 787,\n",
              "             'respect': 788,\n",
              "             'responsible': 789,\n",
              "             'rules': 790,\n",
              "             'seem': 791,\n",
              "             'shootings': 792,\n",
              "             'speaking': 793,\n",
              "             'special': 794,\n",
              "             'spread': 795,\n",
              "             'st': 796,\n",
              "             'standing': 797,\n",
              "             'statement': 798,\n",
              "             'talks': 799,\n",
              "             'threat': 800,\n",
              "             'threats': 801,\n",
              "             'thugs': 802,\n",
              "             'towards': 803,\n",
              "             'united': 804,\n",
              "             'vs': 805,\n",
              "             'ways': 806,\n",
              "             'accountable': 807,\n",
              "             'allegations': 808,\n",
              "             'asked': 809,\n",
              "             'attacking': 810,\n",
              "             'beyond': 811,\n",
              "             'bit': 812,\n",
              "             'boys': 813,\n",
              "             'brought': 814,\n",
              "             'calls': 815,\n",
              "             'claiming': 816,\n",
              "             'companies': 817,\n",
              "             'complete': 818,\n",
              "             'corruption': 819,\n",
              "             'data': 820,\n",
              "             'daughter': 821,\n",
              "             'decades': 822,\n",
              "             'decent': 823,\n",
              "             'desperate': 824,\n",
              "             'died': 825,\n",
              "             'disagree': 826,\n",
              "             'eat': 827,\n",
              "             'economy': 828,\n",
              "             'elections': 829,\n",
              "             'excuse': 830,\n",
              "             'experience': 831,\n",
              "             'forward': 832,\n",
              "             'fox': 833,\n",
              "             'funding': 834,\n",
              "             'girls': 835,\n",
              "             'has': 836,\n",
              "             'hiding': 837,\n",
              "             'honest': 838,\n",
              "             'hurricane': 839,\n",
              "             'ignore': 840,\n",
              "             'keeps': 841,\n",
              "             'kid': 842,\n",
              "             'labour': 843,\n",
              "             'lady': 844,\n",
              "             'leaders': 845,\n",
              "             'light': 846,\n",
              "             'local': 847,\n",
              "             'loves': 848,\n",
              "             'member': 849,\n",
              "             'mention': 850,\n",
              "             'met': 851,\n",
              "             'moral': 852,\n",
              "             'msm': 853,\n",
              "             'muslim': 854,\n",
              "             'narrative': 855,\n",
              "             'national': 856,\n",
              "             'normal': 857,\n",
              "             'notice': 858,\n",
              "             'nuts': 859,\n",
              "             'passed': 860,\n",
              "             'pathetic': 861,\n",
              "             'paying': 862,\n",
              "             'pic': 863,\n",
              "             'plus': 864,\n",
              "             'pm': 865,\n",
              "             'policy': 866,\n",
              "             'pope': 867,\n",
              "             'pot': 868,\n",
              "             'problems': 869,\n",
              "             'safety': 870,\n",
              "             'scared': 871,\n",
              "             'screaming': 872,\n",
              "             'season': 873,\n",
              "             'sensible': 874,\n",
              "             'share': 875,\n",
              "             'simply': 876,\n",
              "             'sir': 877,\n",
              "             'starting': 878,\n",
              "             'student': 879,\n",
              "             'subject': 880,\n",
              "             'successful': 881,\n",
              "             'super': 882,\n",
              "             'supposed': 883,\n",
              "             'tactic': 884,\n",
              "             'tactics': 885,\n",
              "             'target': 886,\n",
              "             'turned': 887,\n",
              "             'victims': 888,\n",
              "             'view': 889,\n",
              "             'votes': 890,\n",
              "             'w': 891,\n",
              "             'within': 892,\n",
              "             'worry': 893,\n",
              "             'yrs': 894,\n",
              "             'accusing': 895,\n",
              "             'administration': 896,\n",
              "             'air': 897,\n",
              "             'anybody': 898,\n",
              "             'arm': 899,\n",
              "             'armed': 900,\n",
              "             'assume': 901,\n",
              "             'bank': 902,\n",
              "             'behavior': 903,\n",
              "             'biggest': 904,\n",
              "             'bully': 905,\n",
              "             'canadian': 906,\n",
              "             'catholic': 907,\n",
              "             'cdnpoli': 908,\n",
              "             'changed': 909,\n",
              "             'cheap': 910,\n",
              "             'collusion': 911,\n",
              "             'comments': 912,\n",
              "             'coward': 913,\n",
              "             'daily': 914,\n",
              "             'democracy': 915,\n",
              "             'deserve': 916,\n",
              "             'deserves': 917,\n",
              "             'destroyed': 918,\n",
              "             'education': 919,\n",
              "             'facebook': 920,\n",
              "             'fair': 921,\n",
              "             'families': 922,\n",
              "             'feelings': 923,\n",
              "             'fellow': 924,\n",
              "             'forever': 925,\n",
              "             'games': 926,\n",
              "             'garbage': 927,\n",
              "             'gov': 928,\n",
              "             'greatest': 929,\n",
              "             'guncontrol': 930,\n",
              "             'haha': 931,\n",
              "             'happening': 932,\n",
              "             'happens': 933,\n",
              "             'hide': 934,\n",
              "             'higher': 935,\n",
              "             'holding': 936,\n",
              "             'hollywood': 937,\n",
              "             'immigrants': 938,\n",
              "             'insane': 939,\n",
              "             'joe': 940,\n",
              "             'knowing': 941,\n",
              "             'lack': 942,\n",
              "             'late': 943,\n",
              "             'living': 944,\n",
              "             'mad': 945,\n",
              "             'major': 946,\n",
              "             'mass': 947,\n",
              "             'mayor': 948,\n",
              "             'meant': 949,\n",
              "             'mentally': 950,\n",
              "             'message': 951,\n",
              "             'minds': 952,\n",
              "             'mine': 953,\n",
              "             'modern': 954,\n",
              "             'moore': 955,\n",
              "             'movie': 956,\n",
              "             'muslims': 957,\n",
              "             'nike': 958,\n",
              "             'nobody': 959,\n",
              "             'nut': 960,\n",
              "             'okay': 961,\n",
              "             'option': 962,\n",
              "             'organization': 963,\n",
              "             'p': 964,\n",
              "             'perhaps': 965,\n",
              "             'personal': 966,\n",
              "             'picture': 967,\n",
              "             'played': 968,\n",
              "             'popular': 969,\n",
              "             'position': 970,\n",
              "             'powerful': 971,\n",
              "             'pr': 972,\n",
              "             'private': 973,\n",
              "             'pure': 974,\n",
              "             'radical': 975,\n",
              "             'reasons': 976,\n",
              "             'represent': 977,\n",
              "             'resist': 978,\n",
              "             'response': 979,\n",
              "             'return': 980,\n",
              "             'saving': 981,\n",
              "             'scotus': 982,\n",
              "             'senate': 983,\n",
              "             'send': 984,\n",
              "             'serious': 985,\n",
              "             'service': 986,\n",
              "             'simple': 987,\n",
              "             'sitting': 988,\n",
              "             'socialism': 989,\n",
              "             'sports': 990,\n",
              "             'stands': 991,\n",
              "             'step': 992,\n",
              "             'suck': 993,\n",
              "             'supreme': 994,\n",
              "             'surprised': 995,\n",
              "             'term': 996,\n",
              "             'test': 997,\n",
              "             'tho': 998,\n",
              "             'tomorrow': 999,\n",
              "             ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIm6Di9vlpXr",
        "outputId": "0345517c-0916-4156-9237-7b9678b11d10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_text.itos"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " 'nt',\n",
              " 'url',\n",
              " 'liberals',\n",
              " 'gun',\n",
              " 'control',\n",
              " 'antifa',\n",
              " 'like',\n",
              " 'maga',\n",
              " 's',\n",
              " 'do',\n",
              " 'people',\n",
              " 'conservatives',\n",
              " 'trump',\n",
              " ' ',\n",
              " 'i',\n",
              " 'one',\n",
              " 'know',\n",
              " 'get',\n",
              " 'would',\n",
              " 'amp',\n",
              " 'think',\n",
              " 'm',\n",
              " 'right',\n",
              " 'good',\n",
              " 'that',\n",
              " 'us',\n",
              " 'shit',\n",
              " 're',\n",
              " 'never',\n",
              " 'going',\n",
              " 'want',\n",
              " 'time',\n",
              " 'really',\n",
              " 'see',\n",
              " 'go',\n",
              " 'need',\n",
              " 'love',\n",
              " 'even',\n",
              " 'you',\n",
              " 'say',\n",
              " 'ca',\n",
              " 'vote',\n",
              " 'way',\n",
              " 'its',\n",
              " 'back',\n",
              " 'make',\n",
              " 'left',\n",
              " 'well',\n",
              " 'much',\n",
              " 'still',\n",
              " 'party',\n",
              " 'he',\n",
              " 'president',\n",
              " 'take',\n",
              " 'look',\n",
              " 'democrats',\n",
              " 'country',\n",
              " 'stop',\n",
              " 'could',\n",
              " 'man',\n",
              " 'years',\n",
              " 'does',\n",
              " 'great',\n",
              " 'nothing',\n",
              " 'also',\n",
              " 'better',\n",
              " 'keep',\n",
              " 'lol',\n",
              " 'many',\n",
              " 'believe',\n",
              " 'another',\n",
              " 'did',\n",
              " 'said',\n",
              " 'u',\n",
              " 'hope',\n",
              " 'thing',\n",
              " 'white',\n",
              " 'away',\n",
              " 'everyone',\n",
              " 'liberal',\n",
              " 've',\n",
              " 'america',\n",
              " 'they',\n",
              " 'care',\n",
              " 'god',\n",
              " 'trying',\n",
              " 'women',\n",
              " 'kavanaugh',\n",
              " 'yes',\n",
              " 'call',\n",
              " 'got',\n",
              " 'is',\n",
              " 'life',\n",
              " 'guns',\n",
              " 'new',\n",
              " 'work',\n",
              " 'every',\n",
              " 'support',\n",
              " 'ever',\n",
              " 'laws',\n",
              " 'money',\n",
              " 'fuck',\n",
              " 'getting',\n",
              " 'since',\n",
              " 'sure',\n",
              " 'ass',\n",
              " 'help',\n",
              " 'thank',\n",
              " 'woman',\n",
              " 'fucking',\n",
              " 'law',\n",
              " 'oh',\n",
              " 'someone',\n",
              " 'everything',\n",
              " 'hate',\n",
              " 'let',\n",
              " 'old',\n",
              " 'please',\n",
              " 'big',\n",
              " 'tell',\n",
              " 'wrong',\n",
              " 'always',\n",
              " 'day',\n",
              " 'she',\n",
              " 'show',\n",
              " 'enough',\n",
              " 'bad',\n",
              " 'first',\n",
              " 'saying',\n",
              " 'give',\n",
              " 'part',\n",
              " 'violence',\n",
              " 'world',\n",
              " 'follow',\n",
              " 'government',\n",
              " 'person',\n",
              " 'funny',\n",
              " 'made',\n",
              " 'anyone',\n",
              " 'come',\n",
              " 'hell',\n",
              " 'news',\n",
              " 'actually',\n",
              " 'american',\n",
              " 'done',\n",
              " 'long',\n",
              " 'may',\n",
              " 'maybe',\n",
              " 'point',\n",
              " 'something',\n",
              " 'truth',\n",
              " 'watch',\n",
              " 'guy',\n",
              " 'job',\n",
              " 'needs',\n",
              " 'anything',\n",
              " 'black',\n",
              " 'game',\n",
              " 'mean',\n",
              " 'obama',\n",
              " 'put',\n",
              " 'talking',\n",
              " 'far',\n",
              " 'real',\n",
              " 'state',\n",
              " 'thought',\n",
              " 'best',\n",
              " 'kind',\n",
              " 'lying',\n",
              " 'making',\n",
              " 'next',\n",
              " 'political',\n",
              " 'start',\n",
              " 'talk',\n",
              " 'things',\n",
              " 'yet',\n",
              " 'dems',\n",
              " 'lies',\n",
              " 'might',\n",
              " 'name',\n",
              " 'stupid',\n",
              " 'true',\n",
              " 'tweet',\n",
              " 'year',\n",
              " 'free',\n",
              " 'lot',\n",
              " 'media',\n",
              " 'says',\n",
              " 'school',\n",
              " 'try',\n",
              " 'beautiful',\n",
              " 'fake',\n",
              " 'lets',\n",
              " 'republicans',\n",
              " 'change',\n",
              " 'conservative',\n",
              " 'd',\n",
              " 'last',\n",
              " 'little',\n",
              " 'looking',\n",
              " 'problem',\n",
              " 'sorry',\n",
              " 'stand',\n",
              " 'use',\n",
              " 'used',\n",
              " 'already',\n",
              " 'find',\n",
              " 'must',\n",
              " 'supporters',\n",
              " 'understand',\n",
              " 'kag',\n",
              " 'reason',\n",
              " 'americans',\n",
              " 'bitch',\n",
              " 'end',\n",
              " 'guess',\n",
              " 'home',\n",
              " 'thanks',\n",
              " 'wo',\n",
              " 'working',\n",
              " 'ask',\n",
              " 'called',\n",
              " 'cause',\n",
              " 'men',\n",
              " 'power',\n",
              " 'yeah',\n",
              " 'sense',\n",
              " 'war',\n",
              " 'group',\n",
              " 'hard',\n",
              " 'liar',\n",
              " 'ok',\n",
              " 'without',\n",
              " 'disgusting',\n",
              " 'exactly',\n",
              " 'family',\n",
              " 'gop',\n",
              " 'happy',\n",
              " 'probably',\n",
              " 'today',\n",
              " 'agree',\n",
              " 'calling',\n",
              " 'crazy',\n",
              " 'knows',\n",
              " 'lie',\n",
              " 'lost',\n",
              " 'means',\n",
              " 'na',\n",
              " 'play',\n",
              " 'remember',\n",
              " 'republican',\n",
              " 'rights',\n",
              " 'absolutely',\n",
              " 'ago',\n",
              " 'comes',\n",
              " 'feel',\n",
              " 'gets',\n",
              " 'girl',\n",
              " 'gon',\n",
              " 'looks',\n",
              " 'seen',\n",
              " 'wants',\n",
              " 'win',\n",
              " 'word',\n",
              " 'around',\n",
              " 'bill',\n",
              " 'else',\n",
              " 'fact',\n",
              " 'makes',\n",
              " 'mind',\n",
              " 'nra',\n",
              " 'ones',\n",
              " 'racist',\n",
              " 'sick',\n",
              " 'twitter',\n",
              " 'using',\n",
              " 'wwgwga',\n",
              " 'amazing',\n",
              " 'crime',\n",
              " 'evil',\n",
              " 'judge',\n",
              " 'public',\n",
              " 'seriously',\n",
              " 'though',\n",
              " 'two',\n",
              " 'walkaway',\n",
              " 'whole',\n",
              " 'are',\n",
              " 'become',\n",
              " 'brexit',\n",
              " 'common',\n",
              " 'constitution',\n",
              " 'democrat',\n",
              " 'either',\n",
              " 'fight',\n",
              " 'guilty',\n",
              " 'heard',\n",
              " 'high',\n",
              " 'house',\n",
              " 'matter',\n",
              " 'seems',\n",
              " 'social',\n",
              " 'violent',\n",
              " 'awesome',\n",
              " 'boy',\n",
              " 'full',\n",
              " 'happen',\n",
              " 'issue',\n",
              " 'live',\n",
              " 'lives',\n",
              " 'open',\n",
              " 'read',\n",
              " 'shot',\n",
              " 'tax',\n",
              " 'there',\n",
              " 'wanted',\n",
              " 'bet',\n",
              " 'blame',\n",
              " 'business',\n",
              " 'coming',\n",
              " 'congress',\n",
              " 'jail',\n",
              " 'kids',\n",
              " 'leave',\n",
              " 'police',\n",
              " 'potus',\n",
              " 'qanon',\n",
              " 'red',\n",
              " 'shooting',\n",
              " 'tcot',\n",
              " 'trumps',\n",
              " 'usa',\n",
              " 'words',\n",
              " 'able',\n",
              " 'book',\n",
              " 'bring',\n",
              " 'children',\n",
              " 'clearly',\n",
              " 'clinton',\n",
              " 'dead',\n",
              " 'different',\n",
              " 'fine',\n",
              " 'found',\n",
              " 'groups',\n",
              " 'hillary',\n",
              " 'hit',\n",
              " 'ill',\n",
              " 'pretty',\n",
              " 'proven',\n",
              " 'question',\n",
              " 'safe',\n",
              " 'took',\n",
              " 'works',\n",
              " 'young',\n",
              " 'act',\n",
              " 'can',\n",
              " 'chicago',\n",
              " 'class',\n",
              " 'cute',\n",
              " 'days',\n",
              " 'facts',\n",
              " 'false',\n",
              " 'following',\n",
              " 'hear',\n",
              " 'hey',\n",
              " 'idiot',\n",
              " 'line',\n",
              " 'listen',\n",
              " 'not',\n",
              " 'paid',\n",
              " 'pay',\n",
              " 'playing',\n",
              " 'politics',\n",
              " 'proud',\n",
              " 'saw',\n",
              " 'speech',\n",
              " 'taking',\n",
              " 'telling',\n",
              " 'via',\n",
              " 'what',\n",
              " 'ai',\n",
              " 'answer',\n",
              " 'behind',\n",
              " 'california',\n",
              " 'case',\n",
              " 'child',\n",
              " 'death',\n",
              " 'deep',\n",
              " 'dude',\n",
              " 'election',\n",
              " 'except',\n",
              " 'holy',\n",
              " 'human',\n",
              " 'imagine',\n",
              " 'kill',\n",
              " 'll',\n",
              " 'place',\n",
              " 'report',\n",
              " 'shut',\n",
              " 'story',\n",
              " 'sucks',\n",
              " 'times',\n",
              " 'wait',\n",
              " 'watching',\n",
              " 'asking',\n",
              " 'church',\n",
              " 'fun',\n",
              " 'head',\n",
              " 'least',\n",
              " 'past',\n",
              " 'realize',\n",
              " 'side',\n",
              " 'th',\n",
              " 'tried',\n",
              " 'was',\n",
              " 'accuser',\n",
              " 'assault',\n",
              " 'attention',\n",
              " 'baby',\n",
              " 'character',\n",
              " 'court',\n",
              " 'deal',\n",
              " 'ford',\n",
              " 'guys',\n",
              " 'history',\n",
              " 'hold',\n",
              " 'innocent',\n",
              " 'instead',\n",
              " 'knew',\n",
              " 'low',\n",
              " 'million',\n",
              " 'nazis',\n",
              " 'poor',\n",
              " 'ruin',\n",
              " 'run',\n",
              " 'sex',\n",
              " 'should',\n",
              " 'shows',\n",
              " 'smart',\n",
              " 'thinks',\n",
              " 'went',\n",
              " 'ya',\n",
              " 'all',\n",
              " 'citizens',\n",
              " 'clear',\n",
              " 'cnn',\n",
              " 'crap',\n",
              " 'criminals',\n",
              " 'destroy',\n",
              " 'donald',\n",
              " 'face',\n",
              " 'fan',\n",
              " 'fascist',\n",
              " 'glad',\n",
              " 'gone',\n",
              " 'hand',\n",
              " 'hands',\n",
              " 'idea',\n",
              " 'less',\n",
              " 'literally',\n",
              " 'lose',\n",
              " 'n',\n",
              " 'nd',\n",
              " 'others',\n",
              " 'patriots',\n",
              " 'r',\n",
              " 'rednationrising',\n",
              " 'second',\n",
              " 'sides',\n",
              " 'terrorist',\n",
              " 'truly',\n",
              " 'turn',\n",
              " 'ur',\n",
              " 'video',\n",
              " 'wonder',\n",
              " 'agenda',\n",
              " 'allow',\n",
              " 'almost',\n",
              " 'attack',\n",
              " 'bc',\n",
              " 'buy',\n",
              " 'canada',\n",
              " 'china',\n",
              " 'damn',\n",
              " 'feinstein',\n",
              " 'hearing',\n",
              " 'miss',\n",
              " 'nation',\n",
              " 'nfl',\n",
              " 'office',\n",
              " 'post',\n",
              " 'race',\n",
              " 'shame',\n",
              " 'soros',\n",
              " 'sounds',\n",
              " 'states',\n",
              " 'thinking',\n",
              " 'together',\n",
              " 'uk',\n",
              " 'victim',\n",
              " 'welcome',\n",
              " 'worst',\n",
              " 'wow',\n",
              " 'abuse',\n",
              " 'argument',\n",
              " 'beat',\n",
              " 'bs',\n",
              " 'bullshit',\n",
              " 'campaign',\n",
              " 'cares',\n",
              " 'check',\n",
              " 'claim',\n",
              " 'corrupt',\n",
              " 'difference',\n",
              " 'elected',\n",
              " 'evidence',\n",
              " 'given',\n",
              " 'goes',\n",
              " 'hopefully',\n",
              " 'hurt',\n",
              " 'illegal',\n",
              " 'important',\n",
              " 'issues',\n",
              " 'known',\n",
              " 'leader',\n",
              " 'lmao',\n",
              " 'murder',\n",
              " 'nazi',\n",
              " 'night',\n",
              " 'none',\n",
              " 'omg',\n",
              " 'order',\n",
              " 'perfect',\n",
              " 'piece',\n",
              " 'policies',\n",
              " 'running',\n",
              " 'sad',\n",
              " 'self',\n",
              " 'soon',\n",
              " 'speak',\n",
              " 'stay',\n",
              " 'strong',\n",
              " 'stuff',\n",
              " 'team',\n",
              " 'texas',\n",
              " 'trash',\n",
              " 'along',\n",
              " 'anymore',\n",
              " 'blue',\n",
              " 'chance',\n",
              " 'correct',\n",
              " 'course',\n",
              " 'dangerous',\n",
              " 'dick',\n",
              " 'disgrace',\n",
              " 'dumb',\n",
              " 'fans',\n",
              " 'fear',\n",
              " 'federal',\n",
              " 'fighting',\n",
              " 'forget',\n",
              " 'gave',\n",
              " 'health',\n",
              " 'joke',\n",
              " 'leftist',\n",
              " 'level',\n",
              " 'likely',\n",
              " 'list',\n",
              " 'majority',\n",
              " 'move',\n",
              " 'movement',\n",
              " 'mr',\n",
              " 'plan',\n",
              " 'proof',\n",
              " 'push',\n",
              " 'ready',\n",
              " 'rest',\n",
              " 'save',\n",
              " 'sexual',\n",
              " 'started',\n",
              " 'supporting',\n",
              " 'top',\n",
              " 'totally',\n",
              " 'tweets',\n",
              " 'voting',\n",
              " 'walk',\n",
              " 'were',\n",
              " 'who',\n",
              " 'worse',\n",
              " 'y',\n",
              " 'actions',\n",
              " 'alone',\n",
              " 'apparently',\n",
              " 'attacks',\n",
              " 'blm',\n",
              " 'carry',\n",
              " 'civil',\n",
              " 'confirmkavanaugh',\n",
              " 'countries',\n",
              " 'criminal',\n",
              " 'defend',\n",
              " 'democratic',\n",
              " 'example',\n",
              " 'friends',\n",
              " 'half',\n",
              " 'heart',\n",
              " 'including',\n",
              " 'justice',\n",
              " 'mouth',\n",
              " 'protect',\n",
              " 'protest',\n",
              " 'rather',\n",
              " 'research',\n",
              " 'stories',\n",
              " 'system',\n",
              " 'taxes',\n",
              " 'terrible',\n",
              " 'tired',\n",
              " 'tories',\n",
              " 'trust',\n",
              " 'winning',\n",
              " '  ',\n",
              " 'allowed',\n",
              " 'amendment',\n",
              " 'b',\n",
              " 'ban',\n",
              " 'bless',\n",
              " 'choice',\n",
              " 'close',\n",
              " 'continue',\n",
              " 'cut',\n",
              " 'dem',\n",
              " 'doubt',\n",
              " 'dr',\n",
              " 'due',\n",
              " 'eric',\n",
              " 'fall',\n",
              " 'fascists',\n",
              " 'fast',\n",
              " 'favorite',\n",
              " 'friend',\n",
              " 'hateful',\n",
              " 'held',\n",
              " 'join',\n",
              " 'killed',\n",
              " 'killing',\n",
              " 'kkk',\n",
              " 'legal',\n",
              " 'loved',\n",
              " 'members',\n",
              " 'millions',\n",
              " 'months',\n",
              " 'november',\n",
              " 'parents',\n",
              " 'politicians',\n",
              " 'ppl',\n",
              " 'prove',\n",
              " 'pussy',\n",
              " 'rape',\n",
              " 'rule',\n",
              " 'schools',\n",
              " 'seeing',\n",
              " 'single',\n",
              " 'socialist',\n",
              " 'society',\n",
              " 'son',\n",
              " 'strict',\n",
              " 'taken',\n",
              " 'takes',\n",
              " 'terrorists',\n",
              " 'total',\n",
              " 'trudeau',\n",
              " 'values',\n",
              " 'voters',\n",
              " 'wanna',\n",
              " 'wing',\n",
              " 'wish',\n",
              " 'zero',\n",
              " 'account',\n",
              " 'age',\n",
              " 'anti',\n",
              " 'based',\n",
              " 'believes',\n",
              " 'bitter',\n",
              " 'break',\n",
              " 'career',\n",
              " 'charge',\n",
              " 'comment',\n",
              " 'completely',\n",
              " 'cool',\n",
              " 'cops',\n",
              " 'crying',\n",
              " 'die',\n",
              " 'dog',\n",
              " 'domestic',\n",
              " 'eu',\n",
              " 'expect',\n",
              " 'father',\n",
              " 'fbi',\n",
              " 'feeling',\n",
              " 'fix',\n",
              " 'followers',\n",
              " 'fool',\n",
              " 'general',\n",
              " 'giving',\n",
              " 'ground',\n",
              " 'happened',\n",
              " 'have',\n",
              " 'holder',\n",
              " 'idk',\n",
              " 'india',\n",
              " 'it',\n",
              " 'jobs',\n",
              " 'moment',\n",
              " 'obviously',\n",
              " 'pass',\n",
              " 'peoples',\n",
              " 'personally',\n",
              " 'process',\n",
              " 'propaganda',\n",
              " 'questions',\n",
              " 'reality',\n",
              " 'resistance',\n",
              " 'set',\n",
              " 'sit',\n",
              " 'speaks',\n",
              " 'students',\n",
              " 'swamp',\n",
              " 'told',\n",
              " 'tv',\n",
              " 'type',\n",
              " 'unless',\n",
              " 'uses',\n",
              " 'v',\n",
              " 'views',\n",
              " 'voted',\n",
              " 'water',\n",
              " 'week',\n",
              " 'whatever',\n",
              " 'wife',\n",
              " 'worth',\n",
              " 'abortion',\n",
              " 'actual',\n",
              " 'afraid',\n",
              " 'alive',\n",
              " 'aware',\n",
              " 'border',\n",
              " 'borders',\n",
              " 'brain',\n",
              " 'broke',\n",
              " 'brown',\n",
              " 'came',\n",
              " 'christian',\n",
              " 'climate',\n",
              " 'crimes',\n",
              " 'culture',\n",
              " 'dc',\n",
              " 'definitely',\n",
              " 'drunk',\n",
              " 'entire',\n",
              " 'fault',\n",
              " 'folks',\n",
              " 'followed',\n",
              " 'form',\n",
              " 'freedom',\n",
              " 'future',\n",
              " 'hat',\n",
              " 'hatred',\n",
              " 'honestly',\n",
              " 'housing',\n",
              " 'hypocrisy',\n",
              " 'investigation',\n",
              " 'longer',\n",
              " 'metoo',\n",
              " 'military',\n",
              " 'names',\n",
              " 'nice',\n",
              " 'opinion',\n",
              " 'platform',\n",
              " 'politically',\n",
              " 'prison',\n",
              " 'pro',\n",
              " 'progressive',\n",
              " 'puerto',\n",
              " 'quite',\n",
              " 'record',\n",
              " 'respect',\n",
              " 'responsible',\n",
              " 'rules',\n",
              " 'seem',\n",
              " 'shootings',\n",
              " 'speaking',\n",
              " 'special',\n",
              " 'spread',\n",
              " 'st',\n",
              " 'standing',\n",
              " 'statement',\n",
              " 'talks',\n",
              " 'threat',\n",
              " 'threats',\n",
              " 'thugs',\n",
              " 'towards',\n",
              " 'united',\n",
              " 'vs',\n",
              " 'ways',\n",
              " 'accountable',\n",
              " 'allegations',\n",
              " 'asked',\n",
              " 'attacking',\n",
              " 'beyond',\n",
              " 'bit',\n",
              " 'boys',\n",
              " 'brought',\n",
              " 'calls',\n",
              " 'claiming',\n",
              " 'companies',\n",
              " 'complete',\n",
              " 'corruption',\n",
              " 'data',\n",
              " 'daughter',\n",
              " 'decades',\n",
              " 'decent',\n",
              " 'desperate',\n",
              " 'died',\n",
              " 'disagree',\n",
              " 'eat',\n",
              " 'economy',\n",
              " 'elections',\n",
              " 'excuse',\n",
              " 'experience',\n",
              " 'forward',\n",
              " 'fox',\n",
              " 'funding',\n",
              " 'girls',\n",
              " 'has',\n",
              " 'hiding',\n",
              " 'honest',\n",
              " 'hurricane',\n",
              " 'ignore',\n",
              " 'keeps',\n",
              " 'kid',\n",
              " 'labour',\n",
              " 'lady',\n",
              " 'leaders',\n",
              " 'light',\n",
              " 'local',\n",
              " 'loves',\n",
              " 'member',\n",
              " 'mention',\n",
              " 'met',\n",
              " 'moral',\n",
              " 'msm',\n",
              " 'muslim',\n",
              " 'narrative',\n",
              " 'national',\n",
              " 'normal',\n",
              " 'notice',\n",
              " 'nuts',\n",
              " 'passed',\n",
              " 'pathetic',\n",
              " 'paying',\n",
              " 'pic',\n",
              " 'plus',\n",
              " 'pm',\n",
              " 'policy',\n",
              " 'pope',\n",
              " 'pot',\n",
              " 'problems',\n",
              " 'safety',\n",
              " 'scared',\n",
              " 'screaming',\n",
              " 'season',\n",
              " 'sensible',\n",
              " 'share',\n",
              " 'simply',\n",
              " 'sir',\n",
              " 'starting',\n",
              " 'student',\n",
              " 'subject',\n",
              " 'successful',\n",
              " 'super',\n",
              " 'supposed',\n",
              " 'tactic',\n",
              " 'tactics',\n",
              " 'target',\n",
              " 'turned',\n",
              " 'victims',\n",
              " 'view',\n",
              " 'votes',\n",
              " 'w',\n",
              " 'within',\n",
              " 'worry',\n",
              " 'yrs',\n",
              " 'accusing',\n",
              " 'administration',\n",
              " 'air',\n",
              " 'anybody',\n",
              " 'arm',\n",
              " 'armed',\n",
              " 'assume',\n",
              " 'bank',\n",
              " 'behavior',\n",
              " 'biggest',\n",
              " 'bully',\n",
              " 'canadian',\n",
              " 'catholic',\n",
              " 'cdnpoli',\n",
              " 'changed',\n",
              " 'cheap',\n",
              " 'collusion',\n",
              " 'comments',\n",
              " 'coward',\n",
              " 'daily',\n",
              " 'democracy',\n",
              " 'deserve',\n",
              " 'deserves',\n",
              " 'destroyed',\n",
              " 'education',\n",
              " 'facebook',\n",
              " 'fair',\n",
              " 'families',\n",
              " 'feelings',\n",
              " 'fellow',\n",
              " 'forever',\n",
              " 'games',\n",
              " 'garbage',\n",
              " 'gov',\n",
              " 'greatest',\n",
              " 'guncontrol',\n",
              " 'haha',\n",
              " 'happening',\n",
              " 'happens',\n",
              " 'hide',\n",
              " 'higher',\n",
              " 'holding',\n",
              " 'hollywood',\n",
              " 'immigrants',\n",
              " 'insane',\n",
              " 'joe',\n",
              " 'knowing',\n",
              " 'lack',\n",
              " 'late',\n",
              " 'living',\n",
              " 'mad',\n",
              " 'major',\n",
              " 'mass',\n",
              " 'mayor',\n",
              " 'meant',\n",
              " 'mentally',\n",
              " 'message',\n",
              " 'minds',\n",
              " 'mine',\n",
              " 'modern',\n",
              " 'moore',\n",
              " 'movie',\n",
              " 'muslims',\n",
              " 'nike',\n",
              " 'nobody',\n",
              " 'nut',\n",
              " 'okay',\n",
              " 'option',\n",
              " 'organization',\n",
              " 'p',\n",
              " 'perhaps',\n",
              " 'personal',\n",
              " 'picture',\n",
              " 'played',\n",
              " 'popular',\n",
              " 'position',\n",
              " 'powerful',\n",
              " 'pr',\n",
              " 'private',\n",
              " 'pure',\n",
              " 'radical',\n",
              " 'reasons',\n",
              " 'represent',\n",
              " 'resist',\n",
              " 'response',\n",
              " 'return',\n",
              " 'saving',\n",
              " 'scotus',\n",
              " 'senate',\n",
              " 'send',\n",
              " 'serious',\n",
              " 'service',\n",
              " 'simple',\n",
              " 'sitting',\n",
              " 'socialism',\n",
              " 'sports',\n",
              " 'stands',\n",
              " 'step',\n",
              " 'suck',\n",
              " 'supreme',\n",
              " 'surprised',\n",
              " 'term',\n",
              " 'test',\n",
              " 'tho',\n",
              " 'tomorrow',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gp4DD8Qlpjm",
        "outputId": "90f66c7c-3e6e-4ed8-b930-90df00c5dd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(vocab_text)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzZxu760lpvD",
        "outputId": "57d7031d-658a-4161-d339-935dfbcd5753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_label = LABEL.vocab\n",
        "vocab_label.stoi"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>, {'0': 0, '1': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhNR_rLglp57",
        "outputId": "5367cfa5-8f8d-4391-9dd1-78648f488eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_label.itos"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEhGmf-mBv5B",
        "outputId": "22a22ccb-f229-4c37-f1ac-2a89d562e2e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld8J1rvcBv2W"
      },
      "source": [
        "train_iter, valid_iter, test_iter = ttd.BucketIterator.splits((train_dataset,valid_dataset,test_dataset), \n",
        "                              sort_key=lambda x: len(x.data),\n",
        "                              #sort_key=None,\n",
        "                              batch_sizes=(32,128,128),\n",
        "                              device=device)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DKWFB87so2t"
      },
      "source": [
        "dataset_test_iter = ttd.BucketIterator(test_1, \n",
        "                              sort_key=lambda x: len(x.data),\n",
        "                              #sort_key=None,\n",
        "                              batch_size=128,\n",
        "                              device='cuda:0')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-qlHicbwpiy",
        "outputId": "df62027a-e8bb-47f3-f1d8-9ae029150762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for batch in dataset_test_iter:\n",
        "  print(\"inputs:\", batch.data, batch.data.shape)\n",
        "  #print(\"targets:\",batch.label, \"shape:\", batch.label.shape)\n",
        "  break"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[   1,    1,    1,  ...,    0,  209, 2570],\n",
            "        [   1,    1,    1,  ...,    0,  401,    9],\n",
            "        [   1,    1,    1,  ...,    1,  121,  526],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    2,   32,    0],\n",
            "        [   1,    1,    1,  ...,  428,  350,  297],\n",
            "        [   1,    1,    1,  ...,   12,  386,   69]], device='cuda:0') torch.Size([128, 33])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru5hrHedBvxg",
        "outputId": "88871863-8a4e-4990-a8d4-3c43537059b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for batch in train_iter:\n",
        "  print(\"inputs:\", batch.data, batch.data.shape)\n",
        "  print(\"targets:\",batch.label, \"shape:\", batch.label.shape)\n",
        "  break"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,  1488,  1332,  9580,   185,\n",
            "           172],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,   213,    91,   292,\n",
            "           228,    11,     2,    18,    32,  7258,  3132,     9,  3030, 10334,\n",
            "             3],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,  4256,    11,     2,   121,\n",
            "             4],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,   473,\n",
            "          1689,    35,   933,  1344,    12,     8,  1051,    57,   128,   181,\n",
            "          9302,   761,  2779,  2316,   476,   445,     8,    49,    35,  1851,\n",
            "          5218],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "          1025],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,  6120,     9,   143,  8402,  5607,  8386,   490, 10330,   447,\n",
            "             3],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     7,    30,  1318,   675,    44,    26,    10,\n",
            "           307,   246,  7453,  3399,   498,  5787,  2372, 10541,   180,    32,\n",
            "          2820],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,   248,    17,   992,  1588,   104,\n",
            "          9372],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,   221,   546,\n",
            "           371,   495,  2378,  6756,  1152,  1130,   554,   137,    72,  6202,\n",
            "          4255],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     8,    13,   179,   295,  6294,  2914,    34,\n",
            "          2130],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,    31,  2797,\n",
            "          4613],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,  2390,  1155, 10681,  5269,  1863,  4209,  1709,  2868,\n",
            "             3],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "          6412,   575,     4,   639,    87,   435,    83,  1948,  4309,   253,\n",
            "            12],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     4,   289,     2,\n",
            "          2361],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,    90,  3905,  2455,    48,    47,   200,\n",
            "           813,    34,    31,   117,   308,   974,   281,  1807,     9,  5694,\n",
            "             3],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,   103,   671,\n",
            "           107],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,  3956,  2624,   345,\n",
            "           141,  2454,  8211,  1795,  1504,  5162,  2425,   502,  1053,  2625,\n",
            "           242],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,  7454,   283,  1193,  6948,    14,    78,\n",
            "           300],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,    73,     2,  4137,   234,     7,\n",
            "          4987],\n",
            "        [    1,  2769,    79,   484,   765,  2956,    14,  3993,  2748,   131,\n",
            "           320,  2312,   600,   765,   543,    99,  3937,  1079,   484,   627,\n",
            "          2137,   484,  2042,  4351,  2048,  1457,  1493,  2614,   320,   484,\n",
            "             9],\n",
            "        [ 2220,  1064,   231,    98,   664,    33,    35,  4080,   447,  4223,\n",
            "             7,  2809,  2250,   615,  2434,  5359,   155,   503,  6377,    20,\n",
            "            41,   154,  9817,  3002,   141,   447,  2575,   154,  2434,  5727,\n",
            "           410],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,    13,\n",
            "             4,  6387,   137,    47,  2131,  1445,   137,     8,    14,   302,\n",
            "          3683],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,  1677,   307,\n",
            "            28, 10420,   176,   245,  1200,  5956,   420,   263,    68,   301,\n",
            "          2428],\n",
            "        [    1,  2499,   405,   329,  4311,   507,  4425,   550,  7592,   199,\n",
            "           530,  4085,   159, 10302,   856,  2294,   600,   968,  1451,  2203,\n",
            "           548,   796,    21,  1251,  1322,  8693,   936,  5375,  7132,    24,\n",
            "           457],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,   511,   275,\n",
            "           409],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,    24,  2800,   238,   286,  5884,    26,    10,  4417,   104,\n",
            "            13],\n",
            "        [    1,     1,     1,     1,   931,     4,   824,    45,  1191,    87,\n",
            "          6435,   725,   508,   199,  1228,  9855,   884,  1839,  2588,  2601,\n",
            "          4971,  3467,  1269,    12,   476,    14,    84,    29,   619,    57,\n",
            "           448],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,   109,    86,    13,   289,     2,  6160,    30,\n",
            "           365,  9231,   243,    12,  1769,   277,  1286,     8,  1501,  1369,\n",
            "            12],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,    11,\n",
            "             2,   562,  4787,  4610,   471,   161,  8651,   266,  7084,   369,\n",
            "          8020],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,    39,  1368,    47,    98,   664,    17,  8918,\n",
            "           660,   338,   867,  1472,  5680,    73,     2,  1745,  1424,  9069,\n",
            "           814],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,    25,   137,  1005,    12,   756,    41,  1489,\n",
            "           139, 10472,  1489,    20,     2,   473,   387,  2258,   784,   867,\n",
            "           498],\n",
            "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,    90,    68,   586,    96,  9160,  5293,    19,\n",
            "          1480,    32,    91,    72,  1253,    35,   933,    36,    79,     4,\n",
            "          1996]], device='cuda:0') torch.Size([32, 31])\n",
            "targets: tensor([0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0') shape: torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tOx6GHwBvvg",
        "outputId": "6777100f-b835-46f6-84a8-6fe2e07cbb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for batch in valid_iter:\n",
        "  print(\"inputs:\", batch.data, batch.data.shape)\n",
        "  print(\"targets:\",batch.label, \"shape:\", batch.label.shape)\n",
        "  break"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[  778,  5409],\n",
            "        [  257,  1318],\n",
            "        [   34,  8784],\n",
            "        [  216,  2011],\n",
            "        [  488,    75],\n",
            "        [   44,   149],\n",
            "        [   36,    79],\n",
            "        [  235,     0],\n",
            "        [ 1764,     0],\n",
            "        [    0,  1028],\n",
            "        [    7,  6650],\n",
            "        [   18,     0],\n",
            "        [  882, 10421],\n",
            "        [  710,   782],\n",
            "        [ 1003,  2995],\n",
            "        [    0,  9254],\n",
            "        [  192,   137],\n",
            "        [ 2590,  2901],\n",
            "        [  193,   143],\n",
            "        [ 3560,    22],\n",
            "        [ 1095,     4],\n",
            "        [ 6718,   170],\n",
            "        [ 1025,     3],\n",
            "        [ 5022,   244],\n",
            "        [   90,     3],\n",
            "        [   15,  3150],\n",
            "        [   86,   618],\n",
            "        [ 1306,     0],\n",
            "        [ 1355,   287],\n",
            "        [    0,   107],\n",
            "        [  103,  1165],\n",
            "        [  138,    28],\n",
            "        [  535,    28],\n",
            "        [ 5490,     0],\n",
            "        [  532,    25],\n",
            "        [ 6889,  2077],\n",
            "        [   38, 10020],\n",
            "        [    1,    38],\n",
            "        [    1,   192],\n",
            "        [    1,   593],\n",
            "        [    1,   509],\n",
            "        [    1,    28],\n",
            "        [    1,  1124],\n",
            "        [    1,  1677],\n",
            "        [    1,  1489],\n",
            "        [    1,   168],\n",
            "        [    1,   511],\n",
            "        [    1,   553],\n",
            "        [    1,   440],\n",
            "        [    1,   509],\n",
            "        [    1,   192],\n",
            "        [    1,  1396],\n",
            "        [    1,    90],\n",
            "        [    1,   235],\n",
            "        [    1,     0],\n",
            "        [    1,     0],\n",
            "        [    1,   235],\n",
            "        [    1,   305],\n",
            "        [    1,   630],\n",
            "        [    1,   215],\n",
            "        [    1,   215],\n",
            "        [    1,     0],\n",
            "        [    1,     0],\n",
            "        [    1,     0],\n",
            "        [    1,     3],\n",
            "        [    1,   103],\n",
            "        [    1,    46],\n",
            "        [    1,     0],\n",
            "        [    1,    13],\n",
            "        [    1,    51],\n",
            "        [    1,    90],\n",
            "        [    1,   123],\n",
            "        [    1,  4172],\n",
            "        [    1,  1545],\n",
            "        [    1,   479],\n",
            "        [    1,  1520],\n",
            "        [    1,   434],\n",
            "        [    1,   556],\n",
            "        [    1,     0],\n",
            "        [    1,   360],\n",
            "        [    1,   360],\n",
            "        [    1,   103],\n",
            "        [    1,   227],\n",
            "        [    1,  5245],\n",
            "        [    1,  2018],\n",
            "        [    1,  7233],\n",
            "        [    1,   916],\n",
            "        [    1,    45],\n",
            "        [    1,  9919],\n",
            "        [    1,   360],\n",
            "        [    1,     0],\n",
            "        [    1,   103],\n",
            "        [    1,  1548],\n",
            "        [    1,   236],\n",
            "        [    1,    90],\n",
            "        [    1,    81],\n",
            "        [    1,   279],\n",
            "        [    1,   532],\n",
            "        [    1,  1665],\n",
            "        [    1,   865],\n",
            "        [    1,   235],\n",
            "        [    1,    61],\n",
            "        [    1,  1262],\n",
            "        [    1,  4161],\n",
            "        [    1,     0],\n",
            "        [    1,  2288],\n",
            "        [    1,   375],\n",
            "        [    1,   103],\n",
            "        [    1,    24],\n",
            "        [    1,  1098],\n",
            "        [    1,   704],\n",
            "        [    1,  1194],\n",
            "        [    1,   182],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1],\n",
            "        [    1,     1]], device='cuda:0') torch.Size([128, 2])\n",
            "targets: tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
            "        0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0') shape: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFDCiRTlBvtS",
        "outputId": "4110dfa4-a14e-4982-9e3e-0194f7642629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for batch in test_iter:\n",
        "  print(\"inputs:\", batch.data[0], batch.data[0].shape)\n",
        "  print(\"targets:\",batch.label, \"shape:\", batch.label.shape)\n",
        "  break"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([5692, 4177], device='cuda:0') torch.Size([2])\n",
            "targets: tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
            "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') shape: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xvblLZpvNSN"
      },
      "source": [
        "**Vanilla RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsqvcIg-pvxt"
      },
      "source": [
        "#Vanilla RNN class\n",
        "#==================\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self, n_vocab, n_embed_dim, n_hidden, n_rnnlayers, n_outputs, dropout_rate):\n",
        "    super(SimpleRNN, self).__init__()\n",
        "    self.D = n_embed_dim\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "    self.V = n_vocab\n",
        "    self.dropout_rate=dropout_rate\n",
        "\n",
        "    # embedding layer\n",
        "    self.embed = nn.Embedding(self.V, self.D)\n",
        "\n",
        "    self.rnn = nn.RNN(\n",
        "        input_size=self.D,\n",
        "        hidden_size=self.M,\n",
        "        num_layers=self.L,\n",
        "        nonlinearity='relu',\n",
        "        batch_first=True)\n",
        "    \n",
        "    self.fc = nn.Linear(self.M, self.K)\n",
        "    \n",
        "    # dropout layer\n",
        "    self.dropout= nn.Dropout(self.dropout_rate)\n",
        "\n",
        "  def forward(self, X):\n",
        "    # initial hidden states\n",
        "    h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    # embedding layer\n",
        "    # turns word indexes into word vectors\n",
        "    # X (batch_size, sentence length)\n",
        "    embedding = self.embed(X)   # (batch_size, sentence_length, emd_dim)\n",
        "    embedding= self.dropout(embedding) # (batch_size, sentence_length, emd_dim)\n",
        "\n",
        "    # get RNN unit output\n",
        "    out, _ = self.rnn(embedding, h0)\n",
        "    #print(res.shape)\n",
        "\n",
        "    # we only want h(T) at the final time step\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    #out = self.fc(out)\n",
        "    return out"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWTXjgoTvMZr",
        "outputId": "95defe73-cf32-48b8-a60f-0fb06963f9c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make some data\n",
        "N = len(TEXT.vocab)\n",
        "T = 7\n",
        "D = 100    \n",
        "M = 150   \n",
        "K = 2  \n",
        "L = 1  #no.of RNN layers  \n",
        "dropout_rate = 0.01  \n",
        "X = np.random.randn(N, T, D)\n",
        "print(X.shape)\n",
        "\n",
        "# Notation\n",
        "# N = number of samples\n",
        "# T = sequence length\n",
        "# D = embedding dimension\n",
        "# M = number of hidden units\n",
        "# K = number of output units"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10902, 7, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY6biT7sx15M",
        "outputId": "8774659f-be1f-4f52-f97a-494f716bf08d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Instantiate the model\n",
        "model = SimpleRNN(n_vocab=N, n_embed_dim=D, n_hidden=M, n_rnnlayers=L, n_outputs=K, dropout_rate=dropout_rate)\n",
        "model.to(device)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleRNN(\n",
              "  (embed): Embedding(10902, 100)\n",
              "  (rnn): RNN(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.01, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUf3UrY62A_K",
        "outputId": "25e25a75-de3f-4159-cf90-48d12e31a7bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleRNN(\n",
            "  (embed): Embedding(10902, 100)\n",
            "  (rnn): RNN(100, 150, batch_first=True)\n",
            "  (fc): Linear(in_features=150, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.01, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE6BHKXE2B70",
        "outputId": "2c9bcecb-8dd2-4550-b364-aeba927bda8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embed.weight torch.Size([10902, 100])\n",
            "rnn.weight_ih_l0 torch.Size([150, 100])\n",
            "rnn.weight_hh_l0 torch.Size([150, 150])\n",
            "rnn.bias_ih_l0 torch.Size([150])\n",
            "rnn.bias_hh_l0 torch.Size([150])\n",
            "fc.weight torch.Size([2, 150])\n",
            "fc.bias torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ingm_2DW2Iuv",
        "outputId": "fffae002-374e-4e0b-9a85-042af23d46f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10902, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I-3ysQP2Vgv",
        "outputId": "7c3e2c30-cc4b-4e5a-de1e-a5347a88ef7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.embed.weight.data.copy_(pretrained_embeddings)   #Initializing weights with Pre-trained embeddings"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.7293e-02,  2.4148e+00, -3.7467e-01,  ..., -5.6043e-01,\n",
              "         -4.2474e-01, -6.4430e-01],\n",
              "        [-2.1092e-03,  1.1528e+00, -6.3001e-01,  ..., -1.2343e+00,\n",
              "          6.8661e-01, -2.0555e-01],\n",
              "        [ 3.1810e-01,  1.0088e+00, -2.6260e-01,  ..., -1.6182e-02,\n",
              "          1.8295e+00, -5.7388e-01],\n",
              "        ...,\n",
              "        [-2.7968e-01,  1.0566e+00,  3.9891e-01,  ..., -5.3530e-01,\n",
              "          7.4959e-01,  1.0814e+00],\n",
              "        [-1.2533e-01, -3.7238e-01, -5.5980e-02,  ...,  3.3211e-01,\n",
              "         -4.0862e-01, -2.7781e-01],\n",
              "        [-5.5559e-01, -1.7610e-02,  6.5311e-01,  ...,  2.4946e-01,\n",
              "         -7.5647e-02,  6.6210e-02]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCEETWBe2Vl4",
        "outputId": "6cb6b82e-7c4a-4d74-a4d7-e1a0d7d42928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model.embed.weight.data[unk_idx] = torch.zeros(D)\n",
        "model.embed.weight.data[pad_idx] = torch.zeros(D)\n",
        "\n",
        "print(model.embed.weight.data)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3181,  1.0088, -0.2626,  ..., -0.0162,  1.8295, -0.5739],\n",
            "        ...,\n",
            "        [-0.2797,  1.0566,  0.3989,  ..., -0.5353,  0.7496,  1.0814],\n",
            "        [-0.1253, -0.3724, -0.0560,  ...,  0.3321, -0.4086, -0.2778],\n",
            "        [-0.5556, -0.0176,  0.6531,  ...,  0.2495, -0.0756,  0.0662]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_XqxGUf7hEX"
      },
      "source": [
        "**Train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgczcmG6654T"
      },
      "source": [
        "learning_rate = 0.005\n",
        "epochs=300\n",
        "\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbfGnspn2Vqw",
        "outputId": "d602890f-3b06-4d21-ca35-c17a739f352b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "patience = 10\n",
        "counter_early_stop = 0\n",
        "best_score = None\n",
        "early_stop = False\n",
        "valid_loss_min = np.Inf\n",
        "delta=0\n",
        "path = folder / 'early_stop_nlp.pt'\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "model.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  scheduler.step()\n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  for batch in train_iter:\n",
        "    # forward pass\n",
        "    output= model(batch.data)\n",
        "    loss=criterion(output,batch.label)\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in valid_iter:\n",
        " \n",
        "      # forward pass\n",
        "      output= model(batch.data)\n",
        "      loss=criterion(output,batch.label)\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')\n",
        "\n",
        "\n",
        "   ## Early Stopping\n",
        "  ##==================\n",
        "    \n",
        "  score = -valid_loss\n",
        "  print(\"Validation loss is {0} and score is {1} \".format(valid_loss, score))\n",
        "\n",
        "  if best_score is None:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model.state_dict(), path)\n",
        "      valid_loss_min = valid_loss\n",
        "      \n",
        "  elif score < best_score + delta:\n",
        "      counter_early_stop += 1\n",
        "\n",
        "      print(\"Inside elif: Score is {0}, Best score is {1} and delta is {2} \".format(score, best_score, delta))\n",
        "\n",
        "      print(f'Early Stopping counter: {counter_early_stop} out of {patience}')\n",
        "      \n",
        "      if counter_early_stop >= patience:\n",
        "          early_stop = True\n",
        "          # un-freeze embeddings - start updating weights when validation losses start to increase\n",
        "          #========================================================================================\n",
        "          model.embed.weight.requires_grad  = True\n",
        "\n",
        "  else:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model.state_dict(), path)\n",
        "      counter_early_stop = 0\n",
        "      valid_loss_min = valid_loss\n",
        "\n",
        "  if early_stop:\n",
        "    print(\"Early stopping\")\n",
        "    break\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300, Train Loss: 0.6139    Valid Loss: 0.5899, Duration: 0:00:00.576688\n",
            "Validation loss is 0.5898895226418972 and score is -0.5898895226418972 \n",
            "Validation loss decreased (inf --> 0.589890).  Saving model ...\n",
            "Epoch 2/300, Train Loss: 0.6263    Valid Loss: 0.5962, Duration: 0:00:00.590661\n",
            "Validation loss is 0.5962082464247942 and score is -0.5962082464247942 \n",
            "Inside elif: Score is -0.5962082464247942, Best score is -0.5898895226418972 and delta is 0 \n",
            "Early Stopping counter: 1 out of 10\n",
            "Epoch 3/300, Train Loss: 0.5514    Valid Loss: 0.5969, Duration: 0:00:00.725441\n",
            "Validation loss is 0.5968974735587835 and score is -0.5968974735587835 \n",
            "Inside elif: Score is -0.5968974735587835, Best score is -0.5898895226418972 and delta is 0 \n",
            "Early Stopping counter: 2 out of 10\n",
            "Epoch 4/300, Train Loss: 0.5057    Valid Loss: 0.5565, Duration: 0:00:00.577882\n",
            "Validation loss is 0.5564957298338413 and score is -0.5564957298338413 \n",
            "Validation loss decreased (0.589890 --> 0.556496).  Saving model ...\n",
            "Epoch 5/300, Train Loss: 0.4146    Valid Loss: 0.5359, Duration: 0:00:00.588099\n",
            "Validation loss is 0.5358502585440874 and score is -0.5358502585440874 \n",
            "Validation loss decreased (0.556496 --> 0.535850).  Saving model ...\n",
            "Epoch 6/300, Train Loss: 0.3919    Valid Loss: 0.5421, Duration: 0:00:00.596095\n",
            "Validation loss is 0.5420777630060911 and score is -0.5420777630060911 \n",
            "Inside elif: Score is -0.5420777630060911, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 1 out of 10\n",
            "Epoch 7/300, Train Loss: 0.3661    Valid Loss: 0.5415, Duration: 0:00:00.579406\n",
            "Validation loss is 0.5415339078754187 and score is -0.5415339078754187 \n",
            "Inside elif: Score is -0.5415339078754187, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 2 out of 10\n",
            "Epoch 8/300, Train Loss: 0.3478    Valid Loss: 0.5464, Duration: 0:00:00.586567\n",
            "Validation loss is 0.5464170482009649 and score is -0.5464170482009649 \n",
            "Inside elif: Score is -0.5464170482009649, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 3 out of 10\n",
            "Epoch 9/300, Train Loss: 0.3335    Valid Loss: 0.5520, Duration: 0:00:00.584735\n",
            "Validation loss is 0.5519658774137497 and score is -0.5519658774137497 \n",
            "Inside elif: Score is -0.5519658774137497, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 4 out of 10\n",
            "Epoch 10/300, Train Loss: 0.3129    Valid Loss: 0.5467, Duration: 0:00:00.592259\n",
            "Validation loss is 0.546704676002264 and score is -0.546704676002264 \n",
            "Inside elif: Score is -0.546704676002264, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 5 out of 10\n",
            "Epoch 11/300, Train Loss: 0.3070    Valid Loss: 0.5500, Duration: 0:00:00.574420\n",
            "Validation loss is 0.5499989166855812 and score is -0.5499989166855812 \n",
            "Inside elif: Score is -0.5499989166855812, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 6 out of 10\n",
            "Epoch 12/300, Train Loss: 0.3049    Valid Loss: 0.5482, Duration: 0:00:00.586456\n",
            "Validation loss is 0.5482154414057732 and score is -0.5482154414057732 \n",
            "Inside elif: Score is -0.5482154414057732, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 7 out of 10\n",
            "Epoch 13/300, Train Loss: 0.3027    Valid Loss: 0.5515, Duration: 0:00:00.576577\n",
            "Validation loss is 0.5514974538236856 and score is -0.5514974538236856 \n",
            "Inside elif: Score is -0.5514974538236856, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 8 out of 10\n",
            "Epoch 14/300, Train Loss: 0.2994    Valid Loss: 0.5530, Duration: 0:00:00.587823\n",
            "Validation loss is 0.5530212987214327 and score is -0.5530212987214327 \n",
            "Inside elif: Score is -0.5530212987214327, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 9 out of 10\n",
            "Epoch 15/300, Train Loss: 0.2955    Valid Loss: 0.5531, Duration: 0:00:00.576956\n",
            "Validation loss is 0.5531352516263723 and score is -0.5531352516263723 \n",
            "Inside elif: Score is -0.5531352516263723, Best score is -0.5358502585440874 and delta is 0 \n",
            "Early Stopping counter: 10 out of 10\n",
            "Early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLSjRkDx2Vtt"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get accuracy and print accuracy\n",
        "def get_accuracy(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct =0 \n",
        "    total =0\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      output=model(batch.data)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct+= (batch.label==indices).sum().item()\n",
        "      total += batch.label.shape[0]\n",
        "    \n",
        "    acc= correct/total\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsnmXpUk2Vpb",
        "outputId": "c874aa64-fbf6-4585-a938-71f9e9cb04a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_acc = get_accuracy(train_iter, model)\n",
        "valid_acc = get_accuracy(valid_iter, model)\n",
        "test_acc = get_accuracy(test_iter ,model)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.8814,\t Valid acc: 0.7555,\t Test acc: 0.7222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLidtiiU2Vjk"
      },
      "source": [
        "# Write a function to get predictions\n",
        "\n",
        "def get_predictions(test_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions= np.array([])\n",
        "    y_test= np.array([])\n",
        "\n",
        "    for batch in test_iter:\n",
        "      \n",
        "      output=model(batch.data)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      predictions=np.concatenate((predictions,indices.cpu().numpy())) \n",
        "      y_test = np.concatenate((y_test,batch.label.cpu().numpy())) \n",
        "      \n",
        "  return y_test, predictions"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMYtvA43yH6C"
      },
      "source": [
        "y_test, predictions=get_predictions(test_iter, model)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is04ztsQyXEu",
        "outputId": "adb9527c-5a8b-4d11-925e-2ab4c8a0a2a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions.max()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtCzsJPRyXHj",
        "outputId": "7f6f0cde-79b1-4bcb-86f5-7acce85444f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1523,  338],\n",
              "       [ 441,  502]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZBLoeNJyXLD"
      },
      "source": [
        "# Write a function to print confusion matrix\n",
        "# plot confusion matrix\n",
        "# need to import confusion_matrix from sklearn for this function to work\n",
        "# need to import seaborn as sns\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true,y_pred,normalize=None):\n",
        "  cm=confusion_matrix(y_true,y_pred,normalize=normalize)\n",
        "  fig, ax = plt.subplots(figsize=(6,5))\n",
        "  if normalize == None:\n",
        "    fmt='d'\n",
        "    fig.suptitle('Confusion matrix without Normalization', fontsize=12)\n",
        "        \n",
        "  else :\n",
        "    fmt='0.2f'\n",
        "    fig.suptitle('Normalized confusion matrix', fontsize=12)\n",
        "    \n",
        "  ax=sns.heatmap(cm,cmap=plt.cm.Blues,annot=True,fmt=fmt)\n",
        "  ax.axhline(y=0, color='k',linewidth=1)\n",
        "  ax.axhline(y=cm.shape[1], color='k',linewidth=2)\n",
        "  ax.axvline(x=0, color='k',linewidth=1)\n",
        "  ax.axvline(x=cm.shape[0], color='k',linewidth=2)\n",
        " \n",
        "  ax.set_xlabel('Predicted label', fontsize=12)\n",
        "  ax.set_ylabel('True label', fontsize=12)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwSOTLxkyW_n",
        "outputId": "414853c7-00b9-4586-b2e6-b9e67838e155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKeltlIsgEGs",
        "outputId": "0c65c500-4be2-4a94-e57e-e48f0ef38b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "true_pos = np.diag(cm)\n",
        "false_pos = np.sum(cm, axis=0) - true_pos\n",
        "false_neg = np.sum(cm, axis=1) - true_pos\n",
        "\n",
        "precision = np.sum(true_pos / (true_pos + false_pos))\n",
        "recall = np.sum(true_pos / (true_pos + false_neg))\n",
        "\n",
        "F2_Measure = (5 * precision * recall) / (4 * precision + recall)\n",
        "F2_Measure"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3551336681402562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGzwrRK5z2NM"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS__JSxBBvrD"
      },
      "source": [
        "# Define the model\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate):\n",
        "    super(RNN, self).__init__()\n",
        "    self.V = n_vocab\n",
        "    self.D = embed_dim\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "    self.num_diections= bidirectional\n",
        "    self.dropout_rate=dropout_rate\n",
        "    \n",
        "    # embedding layer\n",
        "    self.embed = nn.Embedding(self.V, self.D)\n",
        "    \n",
        "    # rnn layers\n",
        "    self.rnn = nn.LSTM(\n",
        "        input_size=self.D,\n",
        "        hidden_size=self.M,\n",
        "        num_layers=self.L,\n",
        "        bidirectional=self.num_diections,\n",
        "        dropout= self.dropout_rate,\n",
        "        batch_first=True)\n",
        "    \n",
        "    # dense layer\n",
        "    if(bidirectional==True):\n",
        "        self.fc = nn.Linear(self.M *2 , self.K)\n",
        "    else:\n",
        "        self.fc = nn.Linear(self.M , self.K)\n",
        "\n",
        "    # dropout layer\n",
        "    self.dropout= nn.Dropout(self.dropout_rate)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    # initial hidden states\n",
        "    if(bidirectional==True):\n",
        "        h0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
        "        c0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
        "    else:  \n",
        "        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "        c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    # embedding layer\n",
        "    # turns word indexes into word vectors\n",
        "    # X (batch_size, sentence length)\n",
        "    embedding = self.embed(X)   # (batch_size, sentence_length, emd_dim)\n",
        "    embedding= self.dropout(embedding) # (batch_size, sentence_length, emd_dim)\n",
        "\n",
        "    # get RNN unit output\n",
        "    output, (hidden,cell) = self.rnn(embedding, (h0, c0))\n",
        "\n",
        "\n",
        "    #output = [batch size, sent len, hid dim * num directions]\n",
        "    #hidden = [num layers * num directions, batch size, hid dim]\n",
        "    #cell = [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "    # max pool\n",
        "    output, _ = torch.max(output, 1)\n",
        "    output= self.dropout(output)\n",
        "    # we only want h(T) at the final time step\n",
        "    output = self.fc(output)\n",
        "    return output"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ7D2e2PBvon"
      },
      "source": [
        "n_vocab = len(TEXT.vocab)\n",
        "embed_dim = 100\n",
        "n_hidden = 150 \n",
        "n_rnnlayers = 3\n",
        "n_outputs = 2\n",
        "bidirectional = False \n",
        "dropout_rate = 0.01 "
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPD5aVOVylQH",
        "outputId": "32a2dcbb-1ab3-4213-cedf-279a397a1734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_LSTM = RNN(n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate=dropout_rate)\n",
        "model_LSTM.to(device)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embed): Embedding(10902, 100)\n",
              "  (rnn): LSTM(100, 150, num_layers=3, batch_first=True, dropout=0.01)\n",
              "  (fc): Linear(in_features=150, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.01, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT32nYIWylGF",
        "outputId": "526542a7-6256-4f6a-c113-c0f3c0e8cdc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in model_LSTM.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embed.weight torch.Size([10902, 100])\n",
            "rnn.weight_ih_l0 torch.Size([600, 100])\n",
            "rnn.weight_hh_l0 torch.Size([600, 150])\n",
            "rnn.bias_ih_l0 torch.Size([600])\n",
            "rnn.bias_hh_l0 torch.Size([600])\n",
            "rnn.weight_ih_l1 torch.Size([600, 150])\n",
            "rnn.weight_hh_l1 torch.Size([600, 150])\n",
            "rnn.bias_ih_l1 torch.Size([600])\n",
            "rnn.bias_hh_l1 torch.Size([600])\n",
            "rnn.weight_ih_l2 torch.Size([600, 150])\n",
            "rnn.weight_hh_l2 torch.Size([600, 150])\n",
            "rnn.bias_ih_l2 torch.Size([600])\n",
            "rnn.bias_hh_l2 torch.Size([600])\n",
            "fc.weight torch.Size([2, 150])\n",
            "fc.bias torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79s7qOg3BvmV",
        "outputId": "e3bb35bc-54a2-4f49-dd19-b410289cda1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_LSTM.embed.weight.data.copy_(pretrained_embeddings)   #Initializing weights with Pre-trained embeddings"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.7293e-02,  2.4148e+00, -3.7467e-01,  ..., -5.6043e-01,\n",
              "         -4.2474e-01, -6.4430e-01],\n",
              "        [-2.1092e-03,  1.1528e+00, -6.3001e-01,  ..., -1.2343e+00,\n",
              "          6.8661e-01, -2.0555e-01],\n",
              "        [ 3.1810e-01,  1.0088e+00, -2.6260e-01,  ..., -1.6182e-02,\n",
              "          1.8295e+00, -5.7388e-01],\n",
              "        ...,\n",
              "        [-2.7968e-01,  1.0566e+00,  3.9891e-01,  ..., -5.3530e-01,\n",
              "          7.4959e-01,  1.0814e+00],\n",
              "        [-1.2533e-01, -3.7238e-01, -5.5980e-02,  ...,  3.3211e-01,\n",
              "         -4.0862e-01, -2.7781e-01],\n",
              "        [-5.5559e-01, -1.7610e-02,  6.5311e-01,  ...,  2.4946e-01,\n",
              "         -7.5647e-02,  6.6210e-02]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDQ-oyOlBvjy",
        "outputId": "96aeeb6d-66b4-4128-d2e8-1c2bed4f2d60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model_LSTM.embed.weight.data[unk_idx] = torch.zeros(embed_dim)\n",
        "model_LSTM.embed.weight.data[pad_idx] = torch.zeros(embed_dim)\n",
        "\n",
        "print(model_LSTM.embed.weight.data)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3181,  1.0088, -0.2626,  ..., -0.0162,  1.8295, -0.5739],\n",
            "        ...,\n",
            "        [-0.2797,  1.0566,  0.3989,  ..., -0.5353,  0.7496,  1.0814],\n",
            "        [-0.1253, -0.3724, -0.0560,  ...,  0.3321, -0.4086, -0.2778],\n",
            "        [-0.5556, -0.0176,  0.6531,  ...,  0.2495, -0.0756,  0.0662]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ULMa94h2TdI"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaaHkb1tBve7"
      },
      "source": [
        "learning_rate = 0.005\n",
        "epochs=300\n",
        "\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "optimizer = torch.optim.Adam(model_LSTM.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of4jtkG-Bvc3",
        "outputId": "162ec0be-0f29-412b-eb21-0bd5deffa9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "patience = 10\n",
        "counter_early_stop = 0\n",
        "best_score = None\n",
        "early_stop = False\n",
        "valid_loss_min = np.Inf\n",
        "delta=0\n",
        "path = folder / 'early_stop_nlp.pt'\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "model_LSTM.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  scheduler.step()\n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model_LSTM.train()\n",
        "  \n",
        "  for batch in train_iter:\n",
        "    # forward pass\n",
        "    output= model_LSTM(batch.data)\n",
        "    loss=criterion(output,batch.label)\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model_LSTM.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in valid_iter:\n",
        " \n",
        "      # forward pass\n",
        "      output= model_LSTM(batch.data)\n",
        "      loss=criterion(output,batch.label)\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')\n",
        "\n",
        "\n",
        "   ## Early Stopping\n",
        "  ##==================\n",
        "    \n",
        "  score = -valid_loss\n",
        "  print(\"Validation loss is {0} and score is {1} \".format(valid_loss, score))\n",
        "\n",
        "  if best_score is None:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model_LSTM.state_dict(), path)\n",
        "      valid_loss_min = valid_loss\n",
        "      \n",
        "  elif score < best_score + delta:\n",
        "      counter_early_stop += 1\n",
        "\n",
        "      print(\"Inside elif: Score is {0}, Best score is {1} and delta is {2} \".format(score, best_score, delta))\n",
        "\n",
        "      print(f'Early Stopping counter: {counter_early_stop} out of {patience}')\n",
        "      \n",
        "      if counter_early_stop >= patience:\n",
        "          early_stop = True\n",
        "          # un-freeze embeddings - start updating weights when validation losses start to increase\n",
        "          #========================================================================================\n",
        "          model_LSTM.embed.weight.requires_grad  = True\n",
        "\n",
        "  else:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model_LSTM.state_dict(), path)\n",
        "      counter_early_stop = 0\n",
        "      valid_loss_min = valid_loss\n",
        "\n",
        "  if early_stop:\n",
        "    print(\"Early stopping\")\n",
        "    break\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300, Train Loss: 0.5937    Valid Loss: 0.5104, Duration: 0:00:01.340433\n",
            "Validation loss is 0.5104416888207197 and score is -0.5104416888207197 \n",
            "Validation loss decreased (inf --> 0.510442).  Saving model ...\n",
            "Epoch 2/300, Train Loss: 0.4958    Valid Loss: 0.5369, Duration: 0:00:01.310820\n",
            "Validation loss is 0.5368681531399488 and score is -0.5368681531399488 \n",
            "Inside elif: Score is -0.5368681531399488, Best score is -0.5104416888207197 and delta is 0 \n",
            "Early Stopping counter: 1 out of 10\n",
            "Epoch 3/300, Train Loss: 0.4604    Valid Loss: 0.4893, Duration: 0:00:01.453375\n",
            "Validation loss is 0.4893475044518709 and score is -0.4893475044518709 \n",
            "Validation loss decreased (0.510442 --> 0.489348).  Saving model ...\n",
            "Epoch 4/300, Train Loss: 0.4052    Valid Loss: 0.5027, Duration: 0:00:01.316816\n",
            "Validation loss is 0.5027033668011427 and score is -0.5027033668011427 \n",
            "Inside elif: Score is -0.5027033668011427, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 1 out of 10\n",
            "Epoch 5/300, Train Loss: 0.3238    Valid Loss: 0.5219, Duration: 0:00:01.332818\n",
            "Validation loss is 0.5219181422144175 and score is -0.5219181422144175 \n",
            "Inside elif: Score is -0.5219181422144175, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 2 out of 10\n",
            "Epoch 6/300, Train Loss: 0.2837    Valid Loss: 0.5439, Duration: 0:00:01.295297\n",
            "Validation loss is 0.5438835751265287 and score is -0.5438835751265287 \n",
            "Inside elif: Score is -0.5438835751265287, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 3 out of 10\n",
            "Epoch 7/300, Train Loss: 0.2529    Valid Loss: 0.5987, Duration: 0:00:01.296747\n",
            "Validation loss is 0.5986736174672842 and score is -0.5986736174672842 \n",
            "Inside elif: Score is -0.5986736174672842, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 4 out of 10\n",
            "Epoch 8/300, Train Loss: 0.2226    Valid Loss: 0.6179, Duration: 0:00:01.413031\n",
            "Validation loss is 0.6178928725421429 and score is -0.6178928725421429 \n",
            "Inside elif: Score is -0.6178928725421429, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 5 out of 10\n",
            "Epoch 9/300, Train Loss: 0.1935    Valid Loss: 0.6393, Duration: 0:00:01.300354\n",
            "Validation loss is 0.6393485683947802 and score is -0.6393485683947802 \n",
            "Inside elif: Score is -0.6393485683947802, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 6 out of 10\n",
            "Epoch 10/300, Train Loss: 0.1701    Valid Loss: 0.6576, Duration: 0:00:01.297620\n",
            "Validation loss is 0.6576233673840761 and score is -0.6576233673840761 \n",
            "Inside elif: Score is -0.6576233673840761, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 7 out of 10\n",
            "Epoch 11/300, Train Loss: 0.1590    Valid Loss: 0.6662, Duration: 0:00:01.373147\n",
            "Validation loss is 0.6661699432879686 and score is -0.6661699432879686 \n",
            "Inside elif: Score is -0.6661699432879686, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 8 out of 10\n",
            "Epoch 12/300, Train Loss: 0.1572    Valid Loss: 0.6820, Duration: 0:00:01.305319\n",
            "Validation loss is 0.6820325758308172 and score is -0.6820325758308172 \n",
            "Inside elif: Score is -0.6820325758308172, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 9 out of 10\n",
            "Epoch 13/300, Train Loss: 0.1534    Valid Loss: 0.6852, Duration: 0:00:01.292788\n",
            "Validation loss is 0.6851578131318092 and score is -0.6851578131318092 \n",
            "Inside elif: Score is -0.6851578131318092, Best score is -0.4893475044518709 and delta is 0 \n",
            "Early Stopping counter: 10 out of 10\n",
            "Early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAq2VzbZBvan",
        "outputId": "0d436127-acd4-4904-a465-0c566efa4206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_acc = get_accuracy(train_iter, model_LSTM)\n",
        "valid_acc = get_accuracy(valid_iter, model_LSTM)\n",
        "test_acc = get_accuracy(test_iter ,model_LSTM)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.9541,\t Valid acc: 0.7723,\t Test acc: 0.7468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iByA7TFxBvYD"
      },
      "source": [
        "y_test, predictions=get_predictions(test_iter, model_LSTM)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqdzA85IBvVH",
        "outputId": "84932158-8d13-4a08-8a3a-3e98fd6259d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1559,  302],\n",
              "       [ 408,  535]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuyaFK3xBvOE",
        "outputId": "3e7122b9-44c4-4219-e7a0-c3e58b93f729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWi5p3b3cE0g",
        "outputId": "f8adb279-0d24-4ca7-ddf8-193525ee4c66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "true_pos = np.diag(cm)\n",
        "false_pos = np.sum(cm, axis=0) - true_pos\n",
        "false_neg = np.sum(cm, axis=1) - true_pos\n",
        "\n",
        "precision = np.sum(true_pos / (true_pos + false_pos))\n",
        "recall = np.sum(true_pos / (true_pos + false_neg))\n",
        "\n",
        "F2_Measure = (5 * precision * recall) / (4 * precision + recall)\n",
        "F2_Measure"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4103209756340078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUbTcIlLdJ2Z"
      },
      "source": [
        "y_act_test, predictions=get_predictions(dataset_test_iter, model_LSTM)   "
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxiCLfy4EBDp",
        "outputId": "aad0ef69-fbe4-4279-e224-c2a2a5a4dbf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2I_fef4EBBH"
      },
      "source": [
        "predictions = np.append(predictions, 0)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imWgYUKBEA-2"
      },
      "source": [
        "df_test1['target']=predictions.astype(int)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNG02sx-EA7u",
        "outputId": "4dd70e56-1706-4e31-eb82-3ae69179b764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_test1['target'].value_counts()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2831\n",
              "1    1063\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaIZDWW1EA5Q",
        "outputId": "b4bf2f63-5765-4299-c252-46e77f3b35a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['labels'].value_counts()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6220\n",
              "1    3126\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz9k6bKHEA18"
      },
      "source": [
        "header = [\"id\", \"target\"]\n",
        "df_test1.to_csv('submission4_1.csv', columns = header, index=False, encoding='utf-8')"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44zlXE99AGcM"
      },
      "source": [
        "**Bidirectional RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfkdJeToAL36"
      },
      "source": [
        "n_vocab = len(TEXT.vocab)\n",
        "embed_dim = 100\n",
        "n_hidden = 150 \n",
        "n_rnnlayers = 4\n",
        "n_outputs = 2\n",
        "bidirectional = True\n",
        "dropout_rate = 0.01 "
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvsVGJ2AL2B",
        "outputId": "dcf2c70c-f729-4fc3-9b5c-8f498562ca24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_BI_RNN = RNN(n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate=dropout_rate)\n",
        "model_BI_RNN.to(device)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embed): Embedding(10902, 100)\n",
              "  (rnn): LSTM(100, 150, num_layers=4, batch_first=True, dropout=0.01, bidirectional=True)\n",
              "  (fc): Linear(in_features=300, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.01, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnmKfeNRALzq",
        "outputId": "03d6e5b0-a3df-4185-81bf-c55a7d190428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in model_BI_RNN.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embed.weight torch.Size([10902, 100])\n",
            "rnn.weight_ih_l0 torch.Size([600, 100])\n",
            "rnn.weight_hh_l0 torch.Size([600, 150])\n",
            "rnn.bias_ih_l0 torch.Size([600])\n",
            "rnn.bias_hh_l0 torch.Size([600])\n",
            "rnn.weight_ih_l0_reverse torch.Size([600, 100])\n",
            "rnn.weight_hh_l0_reverse torch.Size([600, 150])\n",
            "rnn.bias_ih_l0_reverse torch.Size([600])\n",
            "rnn.bias_hh_l0_reverse torch.Size([600])\n",
            "rnn.weight_ih_l1 torch.Size([600, 300])\n",
            "rnn.weight_hh_l1 torch.Size([600, 150])\n",
            "rnn.bias_ih_l1 torch.Size([600])\n",
            "rnn.bias_hh_l1 torch.Size([600])\n",
            "rnn.weight_ih_l1_reverse torch.Size([600, 300])\n",
            "rnn.weight_hh_l1_reverse torch.Size([600, 150])\n",
            "rnn.bias_ih_l1_reverse torch.Size([600])\n",
            "rnn.bias_hh_l1_reverse torch.Size([600])\n",
            "rnn.weight_ih_l2 torch.Size([600, 300])\n",
            "rnn.weight_hh_l2 torch.Size([600, 150])\n",
            "rnn.bias_ih_l2 torch.Size([600])\n",
            "rnn.bias_hh_l2 torch.Size([600])\n",
            "rnn.weight_ih_l2_reverse torch.Size([600, 300])\n",
            "rnn.weight_hh_l2_reverse torch.Size([600, 150])\n",
            "rnn.bias_ih_l2_reverse torch.Size([600])\n",
            "rnn.bias_hh_l2_reverse torch.Size([600])\n",
            "rnn.weight_ih_l3 torch.Size([600, 300])\n",
            "rnn.weight_hh_l3 torch.Size([600, 150])\n",
            "rnn.bias_ih_l3 torch.Size([600])\n",
            "rnn.bias_hh_l3 torch.Size([600])\n",
            "rnn.weight_ih_l3_reverse torch.Size([600, 300])\n",
            "rnn.weight_hh_l3_reverse torch.Size([600, 150])\n",
            "rnn.bias_ih_l3_reverse torch.Size([600])\n",
            "rnn.bias_hh_l3_reverse torch.Size([600])\n",
            "fc.weight torch.Size([2, 300])\n",
            "fc.bias torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuSt9BRLALxM",
        "outputId": "ffad9016-ffe0-42c9-d238-415122f17f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_BI_RNN.embed.weight.data.copy_(pretrained_embeddings)   #Initializing weights with Pre-trained embeddings"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.7293e-02,  2.4148e+00, -3.7467e-01,  ..., -5.6043e-01,\n",
              "         -4.2474e-01, -6.4430e-01],\n",
              "        [-2.1092e-03,  1.1528e+00, -6.3001e-01,  ..., -1.2343e+00,\n",
              "          6.8661e-01, -2.0555e-01],\n",
              "        [ 3.1810e-01,  1.0088e+00, -2.6260e-01,  ..., -1.6182e-02,\n",
              "          1.8295e+00, -5.7388e-01],\n",
              "        ...,\n",
              "        [-2.7968e-01,  1.0566e+00,  3.9891e-01,  ..., -5.3530e-01,\n",
              "          7.4959e-01,  1.0814e+00],\n",
              "        [-1.2533e-01, -3.7238e-01, -5.5980e-02,  ...,  3.3211e-01,\n",
              "         -4.0862e-01, -2.7781e-01],\n",
              "        [-5.5559e-01, -1.7610e-02,  6.5311e-01,  ...,  2.4946e-01,\n",
              "         -7.5647e-02,  6.6210e-02]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_mzn3rwALu7",
        "outputId": "5719e827-60cc-46b2-fc60-10063a4f8b4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model_BI_RNN.embed.weight.data[unk_idx] = torch.zeros(embed_dim)\n",
        "model_BI_RNN.embed.weight.data[pad_idx] = torch.zeros(embed_dim)\n",
        "\n",
        "print(model_BI_RNN.embed.weight.data)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3181,  1.0088, -0.2626,  ..., -0.0162,  1.8295, -0.5739],\n",
            "        ...,\n",
            "        [-0.2797,  1.0566,  0.3989,  ..., -0.5353,  0.7496,  1.0814],\n",
            "        [-0.1253, -0.3724, -0.0560,  ...,  0.3321, -0.4086, -0.2778],\n",
            "        [-0.5556, -0.0176,  0.6531,  ...,  0.2495, -0.0756,  0.0662]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jygcvxV_BluR"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Ba0VOnALs6"
      },
      "source": [
        "learning_rate = 0.005\n",
        "epochs=300\n",
        "\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "optimizer = torch.optim.Adam(model_BI_RNN.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEWGdt9zALqE",
        "outputId": "3a271f22-070e-4ff7-9b8e-c097037a2265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "patience = 10\n",
        "counter_early_stop = 0\n",
        "best_score = None\n",
        "early_stop = False\n",
        "valid_loss_min = np.Inf\n",
        "delta=0\n",
        "path = folder / 'early_stop_nlp.pt'\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "model_BI_RNN.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  scheduler.step()\n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model_BI_RNN.train()\n",
        "  \n",
        "  for batch in train_iter:\n",
        "    # forward pass\n",
        "    output= model_BI_RNN(batch.data)\n",
        "    loss=criterion(output,batch.label)\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model_BI_RNN.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in valid_iter:\n",
        " \n",
        "      # forward pass\n",
        "      output= model_BI_RNN(batch.data)\n",
        "      loss=criterion(output,batch.label)\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')\n",
        "\n",
        "\n",
        "   ## Early Stopping\n",
        "  ##==================\n",
        "    \n",
        "  score = -valid_loss\n",
        "  print(\"Validation loss is {0} and score is {1} \".format(valid_loss, score))\n",
        "\n",
        "  if best_score is None:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model_BI_RNN.state_dict(), path)\n",
        "      valid_loss_min = valid_loss\n",
        "      \n",
        "  elif score < best_score + delta:\n",
        "      counter_early_stop += 1\n",
        "\n",
        "      print(\"Inside elif: Score is {0}, Best score is {1} and delta is {2} \".format(score, best_score, delta))\n",
        "\n",
        "      print(f'Early Stopping counter: {counter_early_stop} out of {patience}')\n",
        "      \n",
        "      if counter_early_stop >= patience:\n",
        "          early_stop = True\n",
        "          # un-freeze embeddings - start updating weights when validation losses start to increase\n",
        "          #========================================================================================\n",
        "          model_BI_RNN.embed.weight.requires_grad  = True\n",
        "\n",
        "  else:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model_BI_RNN.state_dict(), path)\n",
        "      counter_early_stop = 0\n",
        "      valid_loss_min = valid_loss\n",
        "\n",
        "  if early_stop:\n",
        "    print(\"Early stopping\")\n",
        "    break\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300, Train Loss: 0.6052    Valid Loss: 0.5159, Duration: 0:00:03.156503\n",
            "Validation loss is 0.5158927328884602 and score is -0.5158927328884602 \n",
            "Validation loss decreased (inf --> 0.515893).  Saving model ...\n",
            "Epoch 2/300, Train Loss: 0.5015    Valid Loss: 0.4887, Duration: 0:00:03.050250\n",
            "Validation loss is 0.48868346586823463 and score is -0.48868346586823463 \n",
            "Validation loss decreased (0.515893 --> 0.488683).  Saving model ...\n",
            "Epoch 3/300, Train Loss: 0.4596    Valid Loss: 0.4856, Duration: 0:00:03.083491\n",
            "Validation loss is 0.48560722917318344 and score is -0.48560722917318344 \n",
            "Validation loss decreased (0.488683 --> 0.485607).  Saving model ...\n",
            "Epoch 4/300, Train Loss: 0.4212    Valid Loss: 0.5206, Duration: 0:00:03.241860\n",
            "Validation loss is 0.5206015165895224 and score is -0.5206015165895224 \n",
            "Inside elif: Score is -0.5206015165895224, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 1 out of 10\n",
            "Epoch 5/300, Train Loss: 0.3218    Valid Loss: 0.5376, Duration: 0:00:02.999324\n",
            "Validation loss is 0.537628922611475 and score is -0.537628922611475 \n",
            "Inside elif: Score is -0.537628922611475, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 2 out of 10\n",
            "Epoch 6/300, Train Loss: 0.2791    Valid Loss: 0.5859, Duration: 0:00:03.006656\n",
            "Validation loss is 0.5859111454337835 and score is -0.5859111454337835 \n",
            "Inside elif: Score is -0.5859111454337835, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 3 out of 10\n",
            "Epoch 7/300, Train Loss: 0.2410    Valid Loss: 0.6395, Duration: 0:00:03.032080\n",
            "Validation loss is 0.6395196802914143 and score is -0.6395196802914143 \n",
            "Inside elif: Score is -0.6395196802914143, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 4 out of 10\n",
            "Epoch 8/300, Train Loss: 0.2042    Valid Loss: 0.6793, Duration: 0:00:03.063993\n",
            "Validation loss is 0.6792963929474354 and score is -0.6792963929474354 \n",
            "Inside elif: Score is -0.6792963929474354, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 5 out of 10\n",
            "Epoch 9/300, Train Loss: 0.1700    Valid Loss: 0.7644, Duration: 0:00:03.118834\n",
            "Validation loss is 0.7644112072885036 and score is -0.7644112072885036 \n",
            "Inside elif: Score is -0.7644112072885036, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 6 out of 10\n",
            "Epoch 10/300, Train Loss: 0.1332    Valid Loss: 0.7900, Duration: 0:00:03.011736\n",
            "Validation loss is 0.7900060936808586 and score is -0.7900060936808586 \n",
            "Inside elif: Score is -0.7900060936808586, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 7 out of 10\n",
            "Epoch 11/300, Train Loss: 0.1256    Valid Loss: 0.8222, Duration: 0:00:03.159361\n",
            "Validation loss is 0.8221666216850281 and score is -0.8221666216850281 \n",
            "Inside elif: Score is -0.8221666216850281, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 8 out of 10\n",
            "Epoch 12/300, Train Loss: 0.1219    Valid Loss: 0.8422, Duration: 0:00:03.069997\n",
            "Validation loss is 0.8421547040343285 and score is -0.8421547040343285 \n",
            "Inside elif: Score is -0.8421547040343285, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 9 out of 10\n",
            "Epoch 13/300, Train Loss: 0.1157    Valid Loss: 0.8649, Duration: 0:00:02.988161\n",
            "Validation loss is 0.8649094328284264 and score is -0.8649094328284264 \n",
            "Inside elif: Score is -0.8649094328284264, Best score is -0.48560722917318344 and delta is 0 \n",
            "Early Stopping counter: 10 out of 10\n",
            "Early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jiylxrKALnQ",
        "outputId": "ab475941-91ad-4a34-c60a-39623f1b5c1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_acc = get_accuracy(train_iter, model_BI_RNN)\n",
        "valid_acc = get_accuracy(valid_iter, model_BI_RNN)\n",
        "test_acc = get_accuracy(test_iter ,model_BI_RNN)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.9696,\t Valid acc: 0.7667,\t Test acc: 0.7422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NnBf8kFALh8"
      },
      "source": [
        "y_test, predictions=get_predictions(test_iter, model_BI_RNN)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SIivOpTCfeI",
        "outputId": "fe5fe24f-00dc-4ed5-96f4-0cbada931652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1613,  248],\n",
              "       [ 475,  468]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkdiTETPCfcN",
        "outputId": "b65e6c02-6e8e-4480-f44a-73b5554e24e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klfa48KQCfXu"
      },
      "source": [
        "true_pos = np.diag(cm)\n",
        "false_pos = np.sum(cm, axis=0) - true_pos\n",
        "false_neg = np.sum(cm, axis=1) - true_pos\n",
        "\n",
        "precision = np.sum(true_pos / (true_pos + false_pos))\n",
        "recall = np.sum(true_pos / (true_pos + false_neg))"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzOLTgSwCfUs",
        "outputId": "0b71e9ba-d614-4890-ef2b-e7324d9a3193",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "F2_Measure = (5 * precision * recall) / (4 * precision + recall)\n",
        "F2_Measure"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.375198684818124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_1aiJnO5w8A"
      },
      "source": [
        "y_act_test, predictions=get_predictions(dataset_test_iter, model_BI_RNN)   "
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f01PwwJF523F",
        "outputId": "d64b0626-15f0-4384-fadd-28da431eb6f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_act_test"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZr2CMfWNOy2",
        "outputId": "1eca1b99-858c-40ec-d5e8-305890b0d8b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-_Igq2d7gC1"
      },
      "source": [
        "predictions = np.append(predictions, 0)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbhB9rKLNOwn",
        "outputId": "dc81b633-e638-45e3-d876-2769d7b70429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_test1.head()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90194</td>\n",
              "      <td>go home youre drunk maga trump  url</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77444</td>\n",
              "      <td>oh noes tough shit</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13384</td>\n",
              "      <td>canada doesnt need another cuck already enough...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54920</td>\n",
              "      <td>scare every american playing hockey warped puck</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56117</td>\n",
              "      <td>lol throwing bullshit flag nonsense putuporshu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               data  target\n",
              "0  90194                go home youre drunk maga trump  url       1\n",
              "1  77444                                 oh noes tough shit       0\n",
              "2  13384  canada doesnt need another cuck already enough...       1\n",
              "3  54920    scare every american playing hockey warped puck       0\n",
              "4  56117  lol throwing bullshit flag nonsense putuporshu...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlQMbOKwNOro"
      },
      "source": [
        "df_test1['target']=predictions.astype(int)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRuaSi346SYH",
        "outputId": "0c8aefd7-9359-4695-8b77-319f9b51a09e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_test1['target'].value_counts()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2880\n",
              "1    1014\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhGGYvSV6SVg",
        "outputId": "f03b0224-7ae9-4784-d48a-9dfc38d6e268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df['labels'].value_counts()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6220\n",
              "1    3126\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wQq9lh_6SSy",
        "outputId": "9e097212-d1ec-4940-c7a2-699fcc4b3aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_test1.head()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90194</td>\n",
              "      <td>go home youre drunk maga trump  url</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77444</td>\n",
              "      <td>oh noes tough shit</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13384</td>\n",
              "      <td>canada doesnt need another cuck already enough...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54920</td>\n",
              "      <td>scare every american playing hockey warped puck</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56117</td>\n",
              "      <td>lol throwing bullshit flag nonsense putuporshu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               data  target\n",
              "0  90194                go home youre drunk maga trump  url       0\n",
              "1  77444                                 oh noes tough shit       0\n",
              "2  13384  canada doesnt need another cuck already enough...       0\n",
              "3  54920    scare every american playing hockey warped puck       0\n",
              "4  56117  lol throwing bullshit flag nonsense putuporshu...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqp0frw76SN2"
      },
      "source": [
        "header = [\"id\", \"target\"]\n",
        "df_test1.to_csv('submission4-2.csv', columns = header, index=False, encoding='utf-8')"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzjfWUPvF9sU"
      },
      "source": [
        "# CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6girtvoGGBOv"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):        \n",
        "        super().__init__()                \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes                                    \n",
        "                                    ])        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):        \n",
        "        emb = self.embedding(text).unsqueeze(1)        \n",
        "        conved = [F.relu(c(emb)).squeeze(3) for c in self.convs]                \n",
        "        pooled = [F.max_pool1d(c, c.shape[2]).squeeze(2) for c in conved]        \n",
        "        concat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        return self.fc(concat)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYugOsxXGB9_"
      },
      "source": [
        "input_dimensions = len(TEXT.vocab)\n",
        "output_dimensions = 2\n",
        "embed_dim = 100\n",
        "number_of_filters = 80\n",
        "filter_sizes = [1,2]\n",
        "dropout_rate = 0.01\n",
        "\n",
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model_CNN = CNN(input_dimensions, embed_dim, number_of_filters, filter_sizes, output_dimensions, dropout_rate, pad_idx)\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8RSwiSPGCkW",
        "outputId": "9618ed72-a969-4f71-eab4-87e887eafb35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_CNN.to(device)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embedding): Embedding(10902, 100, padding_idx=1)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 80, kernel_size=(1, 100), stride=(1, 1))\n",
              "    (1): Conv2d(1, 80, kernel_size=(2, 100), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=160, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.01, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpVZD6ZnGCyC",
        "outputId": "45211e54-2428-4e67-f6ce-0cc7885f7270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in model_CNN.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding.weight torch.Size([10902, 100])\n",
            "convs.0.weight torch.Size([80, 1, 1, 100])\n",
            "convs.0.bias torch.Size([80])\n",
            "convs.1.weight torch.Size([80, 1, 2, 100])\n",
            "convs.1.bias torch.Size([80])\n",
            "fc.weight torch.Size([2, 160])\n",
            "fc.bias torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8N2BzJXPIxS",
        "outputId": "1ede416e-6a71-41af-90f9-61f93e822979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10902, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuIsrVJdPJee",
        "outputId": "71158b24-1514-447b-c5d4-4c1da0383234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_CNN.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.7293e-02,  2.4148e+00, -3.7467e-01,  ..., -5.6043e-01,\n",
              "         -4.2474e-01, -6.4430e-01],\n",
              "        [-2.1092e-03,  1.1528e+00, -6.3001e-01,  ..., -1.2343e+00,\n",
              "          6.8661e-01, -2.0555e-01],\n",
              "        [ 3.1810e-01,  1.0088e+00, -2.6260e-01,  ..., -1.6182e-02,\n",
              "          1.8295e+00, -5.7388e-01],\n",
              "        ...,\n",
              "        [-2.7968e-01,  1.0566e+00,  3.9891e-01,  ..., -5.3530e-01,\n",
              "          7.4959e-01,  1.0814e+00],\n",
              "        [-1.2533e-01, -3.7238e-01, -5.5980e-02,  ...,  3.3211e-01,\n",
              "         -4.0862e-01, -2.7781e-01],\n",
              "        [-5.5559e-01, -1.7610e-02,  6.5311e-01,  ...,  2.4946e-01,\n",
              "         -7.5647e-02,  6.6210e-02]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiTfHcYvPI5W",
        "outputId": "fa40df75-02ac-4e0b-f1a3-3a3fca2f511b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_CNN.embedding.weight.data[unk_idx] = torch.zeros(embed_dim)\n",
        "model_CNN.embedding.weight.data[pad_idx] = torch.zeros(embed_dim)\n",
        "\n",
        "print(model_CNN.embedding.weight.data)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3181,  1.0088, -0.2626,  ..., -0.0162,  1.8295, -0.5739],\n",
            "        ...,\n",
            "        [-0.2797,  1.0566,  0.3989,  ..., -0.5353,  0.7496,  1.0814],\n",
            "        [-0.1253, -0.3724, -0.0560,  ...,  0.3321, -0.4086, -0.2778],\n",
            "        [-0.5556, -0.0176,  0.6531,  ...,  0.2495, -0.0756,  0.0662]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MyQPuG_QETo"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcXtW46QM5n"
      },
      "source": [
        "learning_rate = 0.005\n",
        "epochs=300\n",
        "\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "optimizer = torch.optim.Adam(model_CNN.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFKbEjAvPI2u",
        "outputId": "04ca573e-cdb8-45a8-ca93-b982d5d2ac66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "patience = 10\n",
        "counter_early_stop = 0\n",
        "best_score = None\n",
        "early_stop = False\n",
        "valid_loss_min = np.Inf\n",
        "delta=0\n",
        "path = folder / 'early_stop_nlp.pt'\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "#model_CNN.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  scheduler.step()\n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model_CNN.train()\n",
        "  for batch in train_iter:\n",
        "   \n",
        "    # forward pass\n",
        "    output= model_CNN(batch.data)    \n",
        "    loss=criterion(output,batch.label)\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model_CNN.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in valid_iter:\n",
        "       # forward pass\n",
        "      output= model_CNN(batch.data)\n",
        "      loss=criterion(output,batch.label)\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')\n",
        "\n",
        "   ## Early Stopping\n",
        "  ##==================\n",
        "    \n",
        "  score = -valid_loss\n",
        "  print(\"Validation loss is {0} and score is {1} \".format(valid_loss, score))\n",
        "\n",
        "  if best_score is None:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model_CNN.state_dict(), path)\n",
        "      valid_loss_min = valid_loss\n",
        "      \n",
        "  elif score < best_score + delta:\n",
        "      counter_early_stop += 1\n",
        "\n",
        "      print(\"Inside elif: Score is {0}, Best score is {1} and delta is {2} \".format(score, best_score, delta))\n",
        "\n",
        "      print(f'Early Stopping counter: {counter_early_stop} out of {patience}')\n",
        "      \n",
        "      if counter_early_stop >= patience:\n",
        "          early_stop = True\n",
        "          # un-freeze embeddings - start updating weights when validation losses start to increase\n",
        "          #========================================================================================\n",
        "          #model_CNN.embed.weight.requires_grad  = True\n",
        "\n",
        "  else:\n",
        "      best_score = score\n",
        "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model_CNN.state_dict(), path)\n",
        "      counter_early_stop = 0\n",
        "      valid_loss_min = valid_loss\n",
        "\n",
        "  if early_stop:\n",
        "    print(\"Early stopping\")\n",
        "    break\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300, Train Loss: 0.5566    Valid Loss: 0.5152, Duration: 0:00:00.648808\n",
            "Validation loss is 0.5151609741151333 and score is -0.5151609741151333 \n",
            "Validation loss decreased (inf --> 0.515161).  Saving model ...\n",
            "Epoch 2/300, Train Loss: 0.3344    Valid Loss: 0.5477, Duration: 0:00:00.538800\n",
            "Validation loss is 0.5477071702480316 and score is -0.5477071702480316 \n",
            "Inside elif: Score is -0.5477071702480316, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 1 out of 10\n",
            "Epoch 3/300, Train Loss: 0.1353    Valid Loss: 0.7444, Duration: 0:00:00.535001\n",
            "Validation loss is 0.7444404680281878 and score is -0.7444404680281878 \n",
            "Inside elif: Score is -0.7444404680281878, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 2 out of 10\n",
            "Epoch 4/300, Train Loss: 0.0464    Valid Loss: 0.9790, Duration: 0:00:00.540275\n",
            "Validation loss is 0.9789819978177547 and score is -0.9789819978177547 \n",
            "Inside elif: Score is -0.9789819978177547, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 3 out of 10\n",
            "Epoch 5/300, Train Loss: 0.0192    Valid Loss: 0.9402, Duration: 0:00:00.524442\n",
            "Validation loss is 0.9401779547333717 and score is -0.9401779547333717 \n",
            "Inside elif: Score is -0.9401779547333717, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 4 out of 10\n",
            "Epoch 6/300, Train Loss: 0.0145    Valid Loss: 0.9663, Duration: 0:00:00.539354\n",
            "Validation loss is 0.9662676006555557 and score is -0.9662676006555557 \n",
            "Inside elif: Score is -0.9662676006555557, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 5 out of 10\n",
            "Epoch 7/300, Train Loss: 0.0121    Valid Loss: 0.9734, Duration: 0:00:00.556370\n",
            "Validation loss is 0.9734227322041988 and score is -0.9734227322041988 \n",
            "Inside elif: Score is -0.9734227322041988, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 6 out of 10\n",
            "Epoch 8/300, Train Loss: 0.0106    Valid Loss: 1.0138, Duration: 0:00:00.536748\n",
            "Validation loss is 1.013833649456501 and score is -1.013833649456501 \n",
            "Inside elif: Score is -1.013833649456501, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 7 out of 10\n",
            "Epoch 9/300, Train Loss: 0.0095    Valid Loss: 1.0186, Duration: 0:00:00.551244\n",
            "Validation loss is 1.018642783164978 and score is -1.018642783164978 \n",
            "Inside elif: Score is -1.018642783164978, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 8 out of 10\n",
            "Epoch 10/300, Train Loss: 0.0084    Valid Loss: 1.0243, Duration: 0:00:00.541845\n",
            "Validation loss is 1.0242590084671974 and score is -1.0242590084671974 \n",
            "Inside elif: Score is -1.0242590084671974, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 9 out of 10\n",
            "Epoch 11/300, Train Loss: 0.0082    Valid Loss: 1.0296, Duration: 0:00:00.536686\n",
            "Validation loss is 1.0296235121786594 and score is -1.0296235121786594 \n",
            "Inside elif: Score is -1.0296235121786594, Best score is -0.5151609741151333 and delta is 0 \n",
            "Early Stopping counter: 10 out of 10\n",
            "Early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjAD7ou3GCZA",
        "outputId": "657e26ca-9d97-43a7-f387-c0c10c2ea465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_acc = get_accuracy(train_iter, model_CNN)\n",
        "valid_acc = get_accuracy(valid_iter, model_CNN)\n",
        "test_acc = get_accuracy(test_iter ,model_CNN)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.9985,\t Valid acc: 0.7458,\t Test acc: 0.7290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or9FhcQ3GBxw"
      },
      "source": [
        "y_test, predictions=get_predictions(test_iter, model_CNN)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF-aZvfxWylU",
        "outputId": "0a6f0c79-1d26-4939-d2f5-daedf1d5f3cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1537,  324],\n",
              "       [ 436,  507]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30tc9xNyWy_Z",
        "outputId": "e503b4a8-f073-4d76-bc37-8f9e3dbc6aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "plot_confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laBGywiiWzLd"
      },
      "source": [
        "true_pos = np.diag(cm)\n",
        "false_pos = np.sum(cm, axis=0) - true_pos\n",
        "false_neg = np.sum(cm, axis=1) - true_pos\n",
        "\n",
        "precision = np.sum(true_pos / (true_pos + false_pos))\n",
        "recall = np.sum(true_pos / (true_pos + false_neg))"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YPbvyGFWzkt",
        "outputId": "d3839949-94d6-4fc9-bf73-e2fb24fd5a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "F2_Measure = (5 * precision * recall) / (4 * precision + recall)\n",
        "F2_Measure"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.368586057409683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiMiu7e6Wzgj"
      },
      "source": [
        "y_act_test, predictions=get_predictions(dataset_test_iter, model_CNN)   "
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekuF4oZSWzcK",
        "outputId": "0fe61b3e-5ddc-4b53-b49c-d00dbb6aca6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUo3yIuCWzG_"
      },
      "source": [
        "predictions = np.append(predictions, 0)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5msQrQMWzD-"
      },
      "source": [
        "df_test1['target']=predictions.astype(int)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3BxJIatWyuS",
        "outputId": "300805b2-5a33-4d50-bac3-a8de10cc2d15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_test1['target'].value_counts()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2824\n",
              "1    1070\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IswoJEOLWyc2"
      },
      "source": [
        "header = [\"id\", \"target\"]\n",
        "df_test1.to_csv('submission3.csv', columns = header, index=False, encoding='utf-8')"
      ],
      "execution_count": 187,
      "outputs": []
    }
  ]
}